==================== fold_0 Training ====================
Epoch 1/200
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2d559f820> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2d559f820> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 15/110 [===>..........................] - ETA: 2s - loss: 13.2925 - val_loss: 13.2925
/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:
The `lr` argument is deprecated, use `learning_rate` instead.
2022-05-10 16:59:09.879997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
110/110 [==============================] - ETA: 0s - loss: 13.0738 - val_loss: 12.9673WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2d559f430> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2d559f430> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
110/110 [==============================] - 3s 23ms/step - loss: 13.0738 - val_loss: 11.9627 - val_val_loss: 11.9055 - _timestamp: 1652173152.0000 - _runtime: 7.0000
Epoch 2/200
110/110 [==============================] - 2s 14ms/step - loss: 11.0943 - val_loss: 11.0061 - _timestamp: 1652173154.0000 - _runtime: 9.0000
Epoch 3/200
110/110 [==============================] - 2s 15ms/step - loss: 10.8930 - val_loss: 10.8030 - _timestamp: 1652173156.0000 - _runtime: 11.0000
Epoch 4/200
110/110 [==============================] - 2s 14ms/step - loss: 10.6357 - val_loss: 10.6003 - _timestamp: 1652173157.0000 - _runtime: 12.0000
Epoch 5/200
110/110 [==============================] - 1s 13ms/step - loss: 10.5749 - val_loss: 10.4958 - _timestamp: 1652173159.0000 - _runtime: 14.0000
Epoch 6/200
110/110 [==============================] - 2s 15ms/step - loss: 10.4095 - val_loss: 10.3384 - _timestamp: 1652173160.0000 - _runtime: 15.0000
Epoch 7/200
110/110 [==============================] - 2s 14ms/step - loss: 10.6222 - val_loss: 10.5504 - _timestamp: 1652173162.0000 - _runtime: 17.0000
Epoch 8/200
110/110 [==============================] - 2s 18ms/step - loss: 10.3983 - val_loss: 10.3167 - _timestamp: 1652173164.0000 - _runtime: 19.0000
Epoch 9/200
110/110 [==============================] - 2s 17ms/step - loss: 10.5141 - val_loss: 11.2132 - _timestamp: 1652173166.0000 - _runtime: 21.0000
Epoch 10/200
110/110 [==============================] - 2s 15ms/step - loss: 10.3688 - val_loss: 10.2965 - _timestamp: 1652173167.0000 - _runtime: 22.0000
Epoch 11/200
110/110 [==============================] - 2s 16ms/step - loss: 10.4827 - val_loss: 10.5056 - _timestamp: 1652173169.0000 - _runtime: 24.0000
Epoch 12/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3699 - val_loss: 10.4275 - _timestamp: 1652173171.0000 - _runtime: 26.0000
Epoch 13/200
110/110 [==============================] - 1s 14ms/step - loss: 10.4639 - val_loss: 10.3936 - _timestamp: 1652173172.0000 - _runtime: 27.0000
Epoch 14/200
110/110 [==============================] - 2s 15ms/step - loss: 10.2967 - val_loss: 10.2080 - _timestamp: 1652173174.0000 - _runtime: 29.0000
Epoch 15/200
110/110 [==============================] - 2s 14ms/step - loss: 10.3629 - val_loss: 10.2839 - _timestamp: 1652173175.0000 - _runtime: 30.0000
Epoch 16/200
110/110 [==============================] - 2s 15ms/step - loss: 10.2250 - val_loss: 10.1519 - _timestamp: 1652173177.0000 - _runtime: 32.0000
Epoch 17/200
110/110 [==============================] - 2s 16ms/step - loss: 10.3267 - val_loss: 10.2953 - _timestamp: 1652173179.0000 - _runtime: 34.0000
Epoch 18/200
110/110 [==============================] - 2s 16ms/step - loss: 10.3149 - val_loss: 10.2389 - _timestamp: 1652173180.0000 - _runtime: 35.0000
Epoch 19/200
110/110 [==============================] - 2s 14ms/step - loss: 10.2800 - val_loss: 10.1987 - _timestamp: 1652173182.0000 - _runtime: 37.0000
Epoch 20/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2439 - val_loss: 10.4338 - _timestamp: 1652173183.0000 - _runtime: 38.0000
Epoch 21/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2235 - val_loss: 10.1522 - _timestamp: 1652173185.0000 - _runtime: 40.0000
Epoch 22/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3342 - val_loss: 10.2898 - _timestamp: 1652173186.0000 - _runtime: 41.0000
Epoch 23/200
110/110 [==============================] - 2s 14ms/step - loss: 10.3223 - val_loss: 10.2436 - _timestamp: 1652173188.0000 - _runtime: 43.0000
Epoch 24/200
110/110 [==============================] - 1s 13ms/step - loss: 10.1917 - val_loss: 10.1169 - _timestamp: 1652173189.0000 - _runtime: 44.0000
Epoch 25/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3756 - val_loss: 10.5963 - _timestamp: 1652173191.0000 - _runtime: 46.0000
Epoch 26/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3138 - val_loss: 10.2366 - _timestamp: 1652173192.0000 - _runtime: 47.0000
Epoch 27/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3458 - val_loss: 10.3677 - _timestamp: 1652173194.0000 - _runtime: 49.0000
Epoch 28/200
110/110 [==============================] - 1s 13ms/step - loss: 10.1867 - val_loss: 10.5217 - _timestamp: 1652173195.0000 - _runtime: 50.0000
Epoch 29/200
110/110 [==============================] - 1s 13ms/step - loss: 10.1769 - val_loss: 10.1006 - _timestamp: 1652173197.0000 - _runtime: 52.0000
Epoch 30/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3649 - val_loss: 10.2894 - _timestamp: 1652173198.0000 - _runtime: 53.0000
Epoch 31/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2923 - val_loss: 10.2140 - _timestamp: 1652173199.0000 - _runtime: 54.0000
Epoch 32/200
110/110 [==============================] - 1s 12ms/step - loss: 10.4021 - val_loss: 10.3239 - _timestamp: 1652173201.0000 - _runtime: 56.0000
Epoch 33/200
110/110 [==============================] - 1s 12ms/step - loss: 10.1774 - val_loss: 10.1008 - _timestamp: 1652173202.0000 - _runtime: 57.0000
Epoch 34/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3084 - val_loss: 10.2737 - _timestamp: 1652173204.0000 - _runtime: 59.0000
Epoch 35/200
110/110 [==============================] - 1s 13ms/step - loss: 10.3044 - val_loss: 10.2204 - _timestamp: 1652173205.0000 - _runtime: 60.0000
Epoch 36/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2347 - val_loss: 10.1534 - _timestamp: 1652173206.0000 - _runtime: 61.0000
Epoch 37/200
110/110 [==============================] - 2s 14ms/step - loss: 10.2733 - val_loss: 10.1928 - _timestamp: 1652173208.0000 - _runtime: 63.0000
Epoch 38/200
 73/110 [==================>...........] - ETA: 0s - loss: 10.1436 - val_loss: 10.1436
110/110 [==============================] - 2s 14ms/step - loss: 10.3327 - val_loss: 10.3229 - _timestamp: 1652173210.0000 - _runtime: 65.0000
Epoch 39/200
110/110 [==============================] - 2s 14ms/step - loss: 10.2896 - val_loss: 10.3572 - _timestamp: 1652173211.0000 - _runtime: 66.0000
Epoch 40/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2018 - val_loss: 10.1138 - _timestamp: 1652173213.0000 - _runtime: 68.0000
Epoch 41/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2101 - val_loss: 10.1292 - _timestamp: 1652173214.0000 - _runtime: 69.0000
Epoch 42/200
Epoch 43/200===========================] - 1s 13ms/step - loss: 10.2612 - val_loss: 10.1834 - _timestamp: 1652173215.0000 - _runtime: 70.0000
Epoch 43/200===========================] - 1s 13ms/step - loss: 10.2612 - val_loss: 10.1834 - _timestamp: 1652173215.0000 - _runtime: 70.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.2115 - val_loss: 10.1370 - _timestamp: 1652173218.0000 - _runtime: 73.0000
Epoch 44/200
110/110 [==============================] - 1s 13ms/step - loss: 10.2115 - val_loss: 10.1370 - _timestamp: 1652173218.0000 - _runtime: 73.0000
Epoch 45/200
110/110 [==============================] - 1s 12ms/step - loss: 10.4509 - val_loss: 10.3688 - _timestamp: 1652173220.0000 - _runtime: 75.0000
Epoch 46/200
 80/110 [====================>.........] - ETA: 0s - loss: 10.5848 - val_loss: 10.5848
110/110 [==============================] - 1s 12ms/step - loss: 10.2439 - val_loss: 10.1849 - _timestamp: 1652173222.0000 - _runtime: 77.0000
Epoch 48/200
 24/110 [=====>........................] - ETA: 1s - loss: 10.8764 - val_loss: 10.8764
 73/110 [==================>...........] - ETA: 0s - loss: 10.5138 - val_loss: 10.5138.1849 - _timestamp: 1652173222.0000 - _runtime: 77.0000
  1/110 [..............................] - ETA: 1s - loss: 14.4944 - val_loss: 14.4944.0003 - _timestamp: 1652173225.0000 - _runtime: 80.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.2367 - val_loss: 10.1929 - _timestamp: 1652173228.0000 - _runtime: 83.0000
 79/110 [====================>.........] - ETA: 0s - loss: 9.6961 - val_loss: 9.6961  .1929 - _timestamp: 1652173228.0000 - _runtime: 83.0000
  1/110 [..............................] - ETA: 1s - loss: 24.1642 - val_loss: 24.1642.4740 - _timestamp: 1652173231.0000 - _runtime: 86.0000
110/110 [==============================] - 2s 15ms/step - loss: 10.2465 - val_loss: 10.1612 - _timestamp: 1652173234.0000 - _runtime: 89.0000
110/110 [==============================] - 2s 15ms/step - loss: 10.2465 - val_loss: 10.1612 - _timestamp: 1652173234.0000 - _runtime: 89.0000
 60/110 [===============>..............] - ETA: 0s - loss: 9.7915 - val_loss: 9.7915  .1612 - _timestamp: 1652173234.0000 - _runtime: 89.0000
110/110 [==============================] - 2s 15ms/step - loss: 10.1852 - val_loss: 10.1109 - _timestamp: 1652173238.0000 - _runtime: 93.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.2440 - val_loss: 10.2428 - _timestamp: 1652173241.0000 - _runtime: 96.0000
 56/110 [==============>...............] - ETA: 0s - loss: 10.3985 - val_loss: 10.3985.2428 - _timestamp: 1652173241.0000 - _runtime: 96.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.3457 - val_loss: 10.2573 - _timestamp: 1652173244.0000 - _runtime: 99.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.3130 - val_loss: 10.2400 - _timestamp: 1652173247.0000 - _runtime: 102.0000
 67/110 [=================>............] - ETA: 0s - loss: 10.2442 - val_loss: 10.2442.2400 - _timestamp: 1652173247.0000 - _runtime: 102.0000
  5/110 [>.............................] - ETA: 1s - loss: 11.9194 - val_loss: 11.9194.0679 - _timestamp: 1652173249.0000 - _runtime: 104.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.3256 - val_loss: 11.8502 - _timestamp: 1652173252.0000 - _runtime: 107.0000
 63/110 [================>.............] - ETA: 0s - loss: 10.7455 - val_loss: 10.7455.8502 - _timestamp: 1652173252.0000 - _runtime: 107.0000
110/110 [==============================] - 2s 15ms/step - loss: 10.2539 - val_loss: 10.1748 - _timestamp: 1652173256.0000 - _runtime: 111.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2056 - val_loss: 10.2346 - _timestamp: 1652173259.0000 - _runtime: 114.0000
 75/110 [===================>..........] - ETA: 0s - loss: 9.8333 - val_loss: 9.8333  .2346 - _timestamp: 1652173259.0000 - _runtime: 114.0000
 14/110 [==>...........................] - ETA: 1s - loss: 8.4519 - val_loss: 8.4519  .2479 - _timestamp: 1652173261.0000 - _runtime: 116.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.2652 - val_loss: 10.1830 - _timestamp: 1652173264.0000 - _runtime: 119.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2926 - val_loss: 10.2524 - _timestamp: 1652173267.0000 - _runtime: 122.0000
 57/110 [==============>...............] - ETA: 0s - loss: 10.0673 - val_loss: 10.0673.2524 - _timestamp: 1652173267.0000 - _runtime: 122.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.1717 - val_loss: 10.1130 - _timestamp: 1652173270.0000 - _runtime: 125.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2480 - val_loss: 10.3180 - _timestamp: 1652173273.0000 - _runtime: 128.0000
 59/110 [===============>..............] - ETA: 0s - loss: 10.0041 - val_loss: 10.0041.3180 - _timestamp: 1652173273.0000 - _runtime: 128.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.1907 - val_loss: 10.2834 - _timestamp: 1652173275.0000 - _runtime: 130.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.1148 - val_loss: 10.0426 - _timestamp: 1652173278.0000 - _runtime: 133.0000
 85/110 [======================>.......] - ETA: 0s - loss: 10.3174 - val_loss: 10.3174.0426 - _timestamp: 1652173278.0000 - _runtime: 133.0000
  9/110 [=>............................] - ETA: 1s - loss: 10.4031 - val_loss: 10.4031.0996 - _timestamp: 1652173281.0000 - _runtime: 136.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.1134 - val_loss: 10.0376 - _timestamp: 1652173284.0000 - _runtime: 139.0000
 84/110 [=====================>........] - ETA: 0s - loss: 10.2484 - val_loss: 10.2484.0376 - _timestamp: 1652173284.0000 - _runtime: 139.0000
 15/110 [===>..........................] - ETA: 1s - loss: 8.7816 - val_loss: 8.7816  .0935 - _timestamp: 1652173287.0000 - _runtime: 142.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2803 - val_loss: 10.1932 - _timestamp: 1652173290.0000 - _runtime: 145.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2803 - val_loss: 10.1932 - _timestamp: 1652173290.0000 - _runtime: 145.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.2694 - val_loss: 10.1838 - _timestamp: 1652173293.0000 - _runtime: 148.0000
 58/110 [==============>...............] - ETA: 0s - loss: 10.9247 - val_loss: 10.9247.1838 - _timestamp: 1652173293.0000 - _runtime: 148.0000
110/110 [==============================] - 1s 14ms/step - loss: 10.0182 - val_loss: 9.9422 - _timestamp: 1652173296.0000 - _runtime: 151.00000
110/110 [==============================] - 2s 14ms/step - loss: 10.2199 - val_loss: 10.3581 - _timestamp: 1652173299.0000 - _runtime: 154.0000
 41/110 [==========>...................] - ETA: 0s - loss: 9.4956 - val_loss: 9.4956  .3581 - _timestamp: 1652173299.0000 - _runtime: 154.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.1886 - val_loss: 10.1335 - _timestamp: 1652173302.0000 - _runtime: 157.0000
105/110 [===========================>..] - ETA: 0s - loss: 10.1554 - val_loss: 10.1554.1335 - _timestamp: 1652173302.0000 - _runtime: 157.0000
 33/110 [========>.....................] - ETA: 1s - loss: 10.5088 - val_loss: 10.5088.0644 - _timestamp: 1652173305.0000 - _runtime: 160.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.2003 - val_loss: 10.1299 - _timestamp: 1652173308.0000 - _runtime: 163.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.4008 - val_loss: 10.3258 - _timestamp: 1652173311.0000 - _runtime: 166.0000
 54/110 [=============>................] - ETA: 0s - loss: 9.9370 - val_loss: 9.9370  .3258 - _timestamp: 1652173311.0000 - _runtime: 166.0000
110/110 [==============================] - 2s 14ms/step - loss: 10.1780 - val_loss: 10.4748 - _timestamp: 1652173314.0000 - _runtime: 169.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.0821 - val_loss: 10.0151 - _timestamp: 1652173317.0000 - _runtime: 172.0000
 72/110 [==================>...........] - ETA: 0s - loss: 10.3738 - val_loss: 10.3738.0151 - _timestamp: 1652173317.0000 - _runtime: 172.0000
 14/110 [==>...........................] - ETA: 1s - loss: 11.0333 - val_loss: 11.0333.1784 - _timestamp: 1652173320.0000 - _runtime: 175.0000
110/110 [==============================] - 1s 13ms/step - loss: 9.9730 - val_loss: 10.1544 - _timestamp: 1652173322.0000 - _runtime: 177.00000
 91/110 [=======================>......] - ETA: 0s - loss: 9.8878 - val_loss: 9.88780.1544 - _timestamp: 1652173322.0000 - _runtime: 177.00000
  5/110 [>.............................] - ETA: 1s - loss: 7.8516 - val_loss: 7.8516.9155 - _timestamp: 1652173325.0000 - _runtime: 180.000000
110/110 [==============================] - 1s 13ms/step - loss: 10.1517 - val_loss: 10.0791 - _timestamp: 1652173328.0000 - _runtime: 183.0000
100/110 [==========================>...] - ETA: 0s - loss: 10.2830 - val_loss: 10.2830.0791 - _timestamp: 1652173328.0000 - _runtime: 183.0000
 36/110 [========>.....................] - ETA: 0s - loss: 9.1314 - val_loss: 9.1314  .1551 - _timestamp: 1652173331.0000 - _runtime: 186.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.0921 - val_loss: 10.8691 - _timestamp: 1652173334.0000 - _runtime: 189.0000
105/110 [===========================>..] - ETA: 0s - loss: 10.3831 - val_loss: 10.3831.8691 - _timestamp: 1652173334.0000 - _runtime: 189.0000
 45/110 [===========>..................] - ETA: 0s - loss: 10.8004 - val_loss: 10.8004.6103 - _timestamp: 1652173337.0000 - _runtime: 192.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.1015 - val_loss: 10.0150 - _timestamp: 1652173340.0000 - _runtime: 195.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.1210 - val_loss: 10.0504 - _timestamp: 1652173342.0000 - _runtime: 197.0000
 94/110 [========================>.....] - ETA: 0s - loss: 9.7370 - val_loss: 9.737010.0504 - _timestamp: 1652173342.0000 - _runtime: 197.0000
 29/110 [======>.......................] - ETA: 0s - loss: 10.3504 - val_loss: 10.3504.0277 - _timestamp: 1652173345.0000 - _runtime: 200.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.1545 - val_loss: 10.0783 - _timestamp: 1652173348.0000 - _runtime: 203.0000
110/110 [==============================] - 1s 12ms/step - loss: 9.9614 - val_loss: 9.9267 - _timestamp: 1652173350.0000 - _runtime: 205.000000
 82/110 [=====================>........] - ETA: 0s - loss: 10.1822 - val_loss: 10.1822267 - _timestamp: 1652173350.0000 - _runtime: 205.000000
 22/110 [=====>........................] - ETA: 1s - loss: 9.6915 - val_loss: 9.6915  .2217 - _timestamp: 1652173353.0000 - _runtime: 208.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.0999 - val_loss: 10.0742 - _timestamp: 1652173356.0000 - _runtime: 211.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.1442 - val_loss: 10.0957 - _timestamp: 1652173359.0000 - _runtime: 214.0000
 64/110 [================>.............] - ETA: 0s - loss: 9.2433 - val_loss: 9.2433  .0957 - _timestamp: 1652173359.0000 - _runtime: 214.0000
  5/110 [>.............................] - ETA: 1s - loss: 10.3803 - val_loss: 10.38039587 - _timestamp: 1652173362.0000 - _runtime: 217.00000
110/110 [==============================] - 1s 13ms/step - loss: 10.0403 - val_loss: 9.9732 - _timestamp: 1652173364.0000 - _runtime: 219.00000
 95/110 [========================>.....] - ETA: 0s - loss: 10.2571 - val_loss: 10.25719732 - _timestamp: 1652173364.0000 - _runtime: 219.00000
 37/110 [=========>....................] - ETA: 0s - loss: 11.1382 - val_loss: 11.1382.0814 - _timestamp: 1652173367.0000 - _runtime: 222.0000
110/110 [==============================] - 1s 13ms/step - loss: 10.0270 - val_loss: 9.9466 - _timestamp: 1652173370.0000 - _runtime: 225.00000
110/110 [==============================] - 1s 12ms/step - loss: 10.2245 - val_loss: 10.1482 - _timestamp: 1652173373.0000 - _runtime: 228.0000
 81/110 [=====================>........] - ETA: 0s - loss: 11.0013 - val_loss: 11.0013.1482 - _timestamp: 1652173373.0000 - _runtime: 228.0000
 21/110 [====>.........................] - ETA: 1s - loss: 12.1230 - val_loss: 12.1230.2876 - _timestamp: 1652173375.0000 - _runtime: 230.0000
110/110 [==============================] - 1s 12ms/step - loss: 10.0696 - val_loss: 9.9994 - _timestamp: 1652173378.0000 - _runtime: 233.00000
110/110 [==============================] - 1s 13ms/step - loss: 10.1988 - val_loss: 10.1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
 58/110 [==============>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 161/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 161/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 161/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 165/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 165/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 168/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 168/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 171/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 171/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 171/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 175/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 175/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 175/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 179/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 179/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 182/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 182/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 182/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 182/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 187/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 187/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 187/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 191/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 191/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 191/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 195/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 195/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 195/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 199/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 199/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Epoch 199/200==========>...............] - ETA: 0s - loss: 9.8946 - val_loss: 9.8946  .1138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()138 - _timestamp: 1652173381.0000 - _runtime: 236.0000
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()138 - _timestamp: 1652173381.0000 - _runtime: 236.0000