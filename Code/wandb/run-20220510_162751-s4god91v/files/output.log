==================== fold_0 Training ====================
Epoch 1/100
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2d6eb18b0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2d6eb18b0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 26/110 [======>.......................] - ETA: 2s - loss: 13.0907 - val_loss: 13.0907
/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning:
The `lr` argument is deprecated, use `learning_rate` instead.
110/110 [==============================] - ETA: 0s - loss: 12.4297 - val_loss: 12.3404WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3aad9fca0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x3aad9fca0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
110/110 [==============================] - 3s 22ms/step - loss: 12.4297 - val_loss: 11.5536 - val_val_loss: 11.5359 - _timestamp: 1652171279.0000 - _runtime: 7.0000
Epoch 2/100
 16/110 [===>..........................] - ETA: 1s - loss: 12.6939 - val_loss: 12.6939
110/110 [==============================] - 2s 14ms/step - loss: 12.0105 - val_loss: 11.9353 - _timestamp: 1652171280.0000 - _runtime: 8.0000
Epoch 3/100
110/110 [==============================] - 1s 13ms/step - loss: 12.0896 - val_loss: 12.0018 - _timestamp: 1652171281.0000 - _runtime: 9.0000
Epoch 4/100
110/110 [==============================] - 1s 13ms/step - loss: 11.8385 - val_loss: 11.7433 - _timestamp: 1652171283.0000 - _runtime: 11.0000
Epoch 5/100
110/110 [==============================] - 1s 13ms/step - loss: 11.6175 - val_loss: 11.5275 - _timestamp: 1652171284.0000 - _runtime: 12.0000
Epoch 6/100
110/110 [==============================] - 1s 13ms/step - loss: 11.3618 - val_loss: 11.2711 - _timestamp: 1652171286.0000 - _runtime: 14.0000
Epoch 7/100
110/110 [==============================] - 2s 15ms/step - loss: 11.3251 - val_loss: 11.2620 - _timestamp: 1652171287.0000 - _runtime: 15.0000
Epoch 8/100
110/110 [==============================] - 2s 14ms/step - loss: 12.1383 - val_loss: 12.0549 - _timestamp: 1652171289.0000 - _runtime: 17.0000
Epoch 9/100
110/110 [==============================] - 2s 14ms/step - loss: 11.1165 - val_loss: 11.0248 - _timestamp: 1652171290.0000 - _runtime: 18.0000
Epoch 10/100
110/110 [==============================] - 2s 14ms/step - loss: 11.2308 - val_loss: 11.2110 - _timestamp: 1652171292.0000 - _runtime: 20.0000
Epoch 11/100
110/110 [==============================] - 1s 13ms/step - loss: 12.1443 - val_loss: 12.1706 - _timestamp: 1652171294.0000 - _runtime: 22.0000
Epoch 12/100
110/110 [==============================] - 1s 13ms/step - loss: 11.8363 - val_loss: 11.7420 - _timestamp: 1652171295.0000 - _runtime: 23.0000
Epoch 13/100
110/110 [==============================] - 1s 13ms/step - loss: 13.3689 - val_loss: 13.3879 - _timestamp: 1652171296.0000 - _runtime: 24.0000
Epoch 14/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0139 - val_loss: 13.9219 - _timestamp: 1652171298.0000 - _runtime: 26.0000
Epoch 15/100
110/110 [==============================] - 1s 14ms/step - loss: 14.0119 - val_loss: 14.1968 - _timestamp: 1652171299.0000 - _runtime: 27.0000
Epoch 16/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0152 - val_loss: 14.0844 - _timestamp: 1652171301.0000 - _runtime: 29.0000
Epoch 17/100
110/110 [==============================] - 2s 14ms/step - loss: 14.0111 - val_loss: 13.8952 - _timestamp: 1652171302.0000 - _runtime: 30.0000
Epoch 18/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0233 - val_loss: 14.0718 - _timestamp: 1652171304.0000 - _runtime: 32.0000
Epoch 19/100
110/110 [==============================] - 2s 14ms/step - loss: 14.0181 - val_loss: 13.9366 - _timestamp: 1652171305.0000 - _runtime: 33.0000
Epoch 20/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0104 - val_loss: 13.9178 - _timestamp: 1652171307.0000 - _runtime: 35.0000
Epoch 21/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0086 - val_loss: 14.0943 - _timestamp: 1652171308.0000 - _runtime: 36.0000
Epoch 22/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0123 - val_loss: 13.9178 - _timestamp: 1652171309.0000 - _runtime: 37.0000
Epoch 23/100
110/110 [==============================] - 1s 14ms/step - loss: 14.0147 - val_loss: 13.9930 - _timestamp: 1652171311.0000 - _runtime: 39.0000
Epoch 24/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0110 - val_loss: 13.9186 - _timestamp: 1652171312.0000 - _runtime: 40.0000
Epoch 25/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0172 - val_loss: 13.9083 - _timestamp: 1652171314.0000 - _runtime: 42.0000
Epoch 26/100
110/110 [==============================] - 1s 12ms/step - loss: 14.0219 - val_loss: 13.9939 - _timestamp: 1652171315.0000 - _runtime: 43.0000
Epoch 27/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0164 - val_loss: 13.9744 - _timestamp: 1652171317.0000 - _runtime: 45.0000
Epoch 28/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0146 - val_loss: 13.8988 - _timestamp: 1652171318.0000 - _runtime: 46.0000
Epoch 29/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0167 - val_loss: 13.9219 - _timestamp: 1652171319.0000 - _runtime: 47.0000
Epoch 30/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0155 - val_loss: 13.9163 - _timestamp: 1652171321.0000 - _runtime: 49.0000
Epoch 31/100
110/110 [==============================] - 2s 15ms/step - loss: 14.0162 - val_loss: 13.9076 - _timestamp: 1652171322.0000 - _runtime: 50.0000
Epoch 32/100
110/110 [==============================] - 2s 14ms/step - loss: 14.0108 - val_loss: 13.8989 - _timestamp: 1652171324.0000 - _runtime: 52.0000
Epoch 33/100
110/110 [==============================] - 2s 15ms/step - loss: 14.0136 - val_loss: 13.9008 - _timestamp: 1652171326.0000 - _runtime: 54.0000
Epoch 34/100
110/110 [==============================] - 1s 13ms/step - loss: 14.0231 - val_loss: 14.1282 - _timestamp: 1652171327.0000 - _runtime: 55.0000
WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x3db069310> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x3db069310> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
==================== fold_0 score ====================
rmse: 31.427301501863347
2022-05-10 16:28:47.732031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.