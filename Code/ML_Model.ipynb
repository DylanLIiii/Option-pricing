{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 机器学习模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "import wandb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import gc \n",
    "from wandb.xgboost import wandb_callback\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class GroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_size : int, default=None\n",
    "        Maximum size for a single training set.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n",
    "    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n",
    "                           'b', 'b', 'b', 'b', 'b',\\\n",
    "                           'c', 'c', 'c', 'c',\\\n",
    "                           'd', 'd', 'd'])\n",
    "    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n",
    "    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n",
    "    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n",
    "                  \"TEST GROUP:\", groups[test_idx])\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n",
    "    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n",
    "    TEST GROUP: ['c' 'c' 'c' 'c']\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n",
    "    TEST: [15, 16, 17]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n",
    "    TEST GROUP: ['d' 'd' 'd']\n",
    "    \"\"\"\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_size=None\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_size = max_train_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "        group_test_size = n_groups // n_folds\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "            for train_group_idx in unique_groups[:group_test_start]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "            train_end = train_array.size\n",
    "            if self.max_train_size and self.max_train_size < train_end:\n",
    "                train_array = train_array[train_end -\n",
    "                                          self.max_train_size:train_end]\n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "\n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    "\n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "\n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Wandb Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### COFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "class CONFIG:\n",
    "    nfold = 5\n",
    "    is_local = True\n",
    "    local_path = '/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Data/Output_data/option/'\n",
    "    local_log_path = '/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/model_nn/log'\n",
    "    colab_path = '/content/'\n",
    "    seed = 42\n",
    "    log_dir = local_log_path + datetime.datetime.now().strftime(r\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "if CONFIG.is_local:\n",
    "    data = pd.read_csv(os.path.join(CONFIG.local_path, '2020_whole.csv'))\n",
    "    \n",
    "else:\n",
    "    data = pd.read_csv(os.path.join(CONFIG.colab_path, '2020_whole.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只用 SP 试试 \n",
    "data_C = data[data['call_put'] == 'c']\n",
    "data_P = data[data['call_put'] == 'p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def setup_cv(df, fold):\n",
    "    \"\"\"return a dataframe with fold index\n",
    "    Use two method here, one with PurgedGroupTimeSeriesSplit(self designed GoupKFold API in scikit-learn), one with TimeSeriesSplit\n",
    "    \n",
    "    To avoid the problem of differents fold with high homogeneity, should use small n_splits:\n",
    "    - If your purpose is performance estimation, you need models with low bias estimates (which means no systematic distortion of estimates). \n",
    "        You can achieve this by using a higher number of folds, usually between 10 and 20.\n",
    "    - If your aim is parameter tuning, you need a mix of bias and variance, so it is advisable to use a medium number of folds, usually between 5 and 7.\n",
    "    - If your purpose is just to apply variable selection and simplify your dataset, you need models with low variance estimates (or you will have disagreement). \n",
    "        Hence, a lower number of folds will suffice, usually between 3 and 5.\n",
    "    \n",
    "    To simulate the generation of time window, use large n_splits, the step can be numbers of sample(n) // n_splits\n",
    "    e.g. when n_splits = n, step = n // n = 1\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe with time window\n",
    "        fold (int): fold number\n",
    "\n",
    "    Returns:\n",
    "        dataframe: dataframe with fold index\n",
    "    \"\"\"\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df.sort_values(by='Date', inplace = True)\n",
    "    df['fold'] = -1\n",
    "    if len(data.underlying.unique()) > 1:\n",
    "        cv = PurgedGroupTimeSeriesSplit(n_splits=fold, group_gap=0)\n",
    "        step = df.shape[0]//fold\n",
    "        print(f\"{'=' * 20} step : {step} {'=' * 20}\")\n",
    "        for index, (train_, val_) in enumerate(cv.split(df, groups=df.underlying)):\n",
    "            print(f\"{'=' * 20} val_{index} {'=' * 20}\")\n",
    "            print(val_[-50:])\n",
    "            df.iloc[val_, -1] = index\n",
    "    else :\n",
    "        cv = TimeSeriesSplit(n_splits=fold)\n",
    "        step = df.shape[0]//fold\n",
    "        print(f\"{'=' * 20} step : {step} {'=' * 20}\")\n",
    "        for index, (train_, val_) in enumerate(cv.split(df)):\n",
    "            print(f\"{'=' * 20} val_{index} {'=' * 20}\")\n",
    "            print(val_[-50:])\n",
    "            df.iloc[val_, -1] = index\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== step : 420628 ====================\n",
      "==================== val_0 ====================\n",
      "[2101825, 2101826, 2101827, 2101828, 2101829, 2101830, 2101831, 2101832, 2101833, 2102562, 2102563, 2102564, 2102565, 2102566, 2102567, 2102568, 2102569, 2102570, 2102571, 2102572, 2102573, 2102574, 2102575, 2102576, 2102577, 2102578, 2102579, 2102580, 2102581, 2102586, 2102587, 2102588, 2102589, 2102590, 2102591, 2102592, 2102593, 2102594, 2102595, 2102596, 2102597, 2102598, 2102599, 2102600, 2102601, 2102602, 2102603, 2102604, 2102605, 2102606]\n",
      "==================== val_1 ====================\n",
      "[2097621, 2097622, 2097623, 2097624, 2097625, 2097626, 2097627, 2097628, 2097629, 2097630, 2097631, 2097632, 2097633, 2097634, 2097635, 2097636, 2097637, 2097638, 2097639, 2097640, 2097641, 2097642, 2097643, 2097644, 2097645, 2097646, 2097647, 2097648, 2097649, 2097650, 2097651, 2097652, 2097653, 2097654, 2097655, 2097656, 2097657, 2097658, 2097659, 2097660, 2097661, 2097662, 2097663, 2097664, 2097665, 2097666, 2097667, 2097668, 2097669, 2097670]\n",
      "==================== val_2 ====================\n",
      "[2097267, 2097268, 2097269, 2097270, 2097271, 2097272, 2097273, 2097274, 2097275, 2097276, 2097277, 2097278, 2097279, 2097280, 2097281, 2097282, 2097283, 2097284, 2097285, 2097286, 2097287, 2097288, 2097289, 2097290, 2097291, 2097292, 2097293, 2097294, 2097295, 2097296, 2097297, 2097298, 2097299, 2097300, 2097301, 2102582, 2102583, 2102584, 2102585, 2102736, 2102737, 2102738, 2102739, 2102740, 2102741, 2102742, 2102743, 2102744, 2102745, 2102746]\n",
      "==================== val_3 ====================\n",
      "[1931660, 1931962, 1955949, 1961590, 1971749, 1971799, 1982660, 1982661, 1982741, 1982742, 1991774, 1991836, 2002032, 2005235, 2011260, 2011261, 2020426, 2020491, 2020492, 2020493, 2033271, 2033273, 2033274, 2038341, 2038417, 2038418, 2048814, 2048815, 2048816, 2059128, 2059189, 2059396, 2062407, 2062408, 2062409, 2062755, 2062756, 2062757, 2062758, 2062759, 2067840, 2068237, 2076438, 2077249, 2077250, 2077251, 2085026, 2085254, 2102618, 2103141]\n",
      "==================== val_4 ====================\n",
      "[2103091, 2103092, 2103093, 2103094, 2103095, 2103096, 2103097, 2103098, 2103099, 2103100, 2103101, 2103102, 2103103, 2103104, 2103105, 2103106, 2103107, 2103108, 2103109, 2103110, 2103111, 2103112, 2103113, 2103114, 2103115, 2103116, 2103117, 2103118, 2103119, 2103120, 2103121, 2103122, 2103123, 2103124, 2103125, 2103126, 2103127, 2103128, 2103129, 2103130, 2103131, 2103132, 2103133, 2103134, 2103135, 2103136, 2103137, 2103138, 2103139, 2103140]\n"
     ]
    }
   ],
   "source": [
    "data_C = setup_cv(data, CONFIG.nfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  2,  0,  3,  4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_C.fold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Date', 'underlying', 'exchange',\n",
       "       'root_symbol', 'futures_symbol', 'fut_expiration_date', 'futures_close',\n",
       "       'opt_expiration_date', 'strike', 'call_put', 'style', 'bid', 'ask',\n",
       "       'settlement', 'volume', 'open_interest', '1M', '3M', '6M', '12M',\n",
       "       'fold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_C.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个标的的RV\n",
    "def cal_rv(df):\n",
    "    \"\"\"return rv of each unerlying\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): df with rv\n",
    "    \"\"\"\n",
    "    df_time = df.drop_duplicates(subset=['Date'], keep='first', inplace=False)\n",
    "    df_time['sigma'] = np.std(df_time.futures_close.pct_change(1))\n",
    "    dict_ = df_time[['Date', 'sigma']].set_index('Date').to_dict()['sigma']\n",
    "    \n",
    "    df['sigma'] = df['Date'].map(dict_)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# features and target\n",
    "\n",
    "data_C = data_C.groupby('underlying').apply(cal_rv)\n",
    "data_C['S_K'] = data_C.strike / data_C.futures_close\n",
    "data_C.Date = pd.to_datetime(data_C.Date)\n",
    "data_C.opt_expiration_date = pd.to_datetime(data_C.opt_expiration_date)\n",
    "data_C['days'] = (data_C.opt_expiration_date - data_C.Date).dt.days/365\n",
    "\n",
    "features = ['S_K', 'days', 'sigma', '12M']\n",
    "target = ['settlement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>underlying</th>\n",
       "      <th>exchange</th>\n",
       "      <th>root_symbol</th>\n",
       "      <th>futures_symbol</th>\n",
       "      <th>fut_expiration_date</th>\n",
       "      <th>futures_close</th>\n",
       "      <th>opt_expiration_date</th>\n",
       "      <th>...</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>1M</th>\n",
       "      <th>3M</th>\n",
       "      <th>6M</th>\n",
       "      <th>12M</th>\n",
       "      <th>fold</th>\n",
       "      <th>sigma</th>\n",
       "      <th>S_K</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1569641</td>\n",
       "      <td>1569641</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>DA</td>\n",
       "      <td>CME</td>\n",
       "      <td>DA</td>\n",
       "      <td>DA/20F.CM</td>\n",
       "      <td>02/05/2020</td>\n",
       "      <td>17.059999</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>413</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.126342</td>\n",
       "      <td>0.937866</td>\n",
       "      <td>0.093151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1572300</td>\n",
       "      <td>1572300</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW</td>\n",
       "      <td>ES/20M.CM</td>\n",
       "      <td>06/19/2020</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.080086</td>\n",
       "      <td>0.326027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1572299</td>\n",
       "      <td>1572299</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW</td>\n",
       "      <td>ES/20M.CM</td>\n",
       "      <td>06/19/2020</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.077017</td>\n",
       "      <td>0.326027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1572298</td>\n",
       "      <td>1572298</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW</td>\n",
       "      <td>ES/20M.CM</td>\n",
       "      <td>06/19/2020</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.073949</td>\n",
       "      <td>0.326027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1572297</td>\n",
       "      <td>1572297</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW</td>\n",
       "      <td>ES/20M.CM</td>\n",
       "      <td>06/19/2020</td>\n",
       "      <td>3259.000000</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>1.070881</td>\n",
       "      <td>0.326027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103137</th>\n",
       "      <td>1018733</td>\n",
       "      <td>1018733</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW2</td>\n",
       "      <td>ES/20Z.CM</td>\n",
       "      <td>12/18/2020</td>\n",
       "      <td>3632.750000</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>223</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>0.046575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103138</th>\n",
       "      <td>1018734</td>\n",
       "      <td>1018734</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW2</td>\n",
       "      <td>ES/20Z.CM</td>\n",
       "      <td>12/18/2020</td>\n",
       "      <td>3632.750000</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>6061</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.920790</td>\n",
       "      <td>0.046575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103139</th>\n",
       "      <td>1018735</td>\n",
       "      <td>1018735</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW2</td>\n",
       "      <td>ES/20Z.CM</td>\n",
       "      <td>12/18/2020</td>\n",
       "      <td>3632.750000</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>420</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.922166</td>\n",
       "      <td>0.046575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103140</th>\n",
       "      <td>1018725</td>\n",
       "      <td>1018725</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>ES</td>\n",
       "      <td>CME</td>\n",
       "      <td>EW2</td>\n",
       "      <td>ES/20Z.CM</td>\n",
       "      <td>12/18/2020</td>\n",
       "      <td>3632.750000</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>242</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.867112</td>\n",
       "      <td>0.046575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103141</th>\n",
       "      <td>1014297</td>\n",
       "      <td>1014297</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>NG</td>\n",
       "      <td>NYMEX</td>\n",
       "      <td>NG</td>\n",
       "      <td>NG/20Z.NX</td>\n",
       "      <td>11/25/2020</td>\n",
       "      <td>2.775000</td>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3</td>\n",
       "      <td>0.177440</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2103142 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0.1  Unnamed: 0       Date underlying exchange root_symbol  \\\n",
       "0             1569641     1569641 2020-01-02         DA      CME          DA   \n",
       "1             1572300     1572300 2020-01-02         ES      CME          EW   \n",
       "2             1572299     1572299 2020-01-02         ES      CME          EW   \n",
       "3             1572298     1572298 2020-01-02         ES      CME          EW   \n",
       "4             1572297     1572297 2020-01-02         ES      CME          EW   \n",
       "...               ...         ...        ...        ...      ...         ...   \n",
       "2103137       1018733     1018733 2020-11-24         ES      CME         EW2   \n",
       "2103138       1018734     1018734 2020-11-24         ES      CME         EW2   \n",
       "2103139       1018735     1018735 2020-11-24         ES      CME         EW2   \n",
       "2103140       1018725     1018725 2020-11-24         ES      CME         EW2   \n",
       "2103141       1014297     1014297 2020-11-24         NG    NYMEX          NG   \n",
       "\n",
       "        futures_symbol fut_expiration_date  futures_close opt_expiration_date  \\\n",
       "0            DA/20F.CM          02/05/2020      17.059999          2020-02-05   \n",
       "1            ES/20M.CM          06/19/2020    3259.000000          2020-04-30   \n",
       "2            ES/20M.CM          06/19/2020    3259.000000          2020-04-30   \n",
       "3            ES/20M.CM          06/19/2020    3259.000000          2020-04-30   \n",
       "4            ES/20M.CM          06/19/2020    3259.000000          2020-04-30   \n",
       "...                ...                 ...            ...                 ...   \n",
       "2103137      ES/20Z.CM          12/18/2020    3632.750000          2020-12-11   \n",
       "2103138      ES/20Z.CM          12/18/2020    3632.750000          2020-12-11   \n",
       "2103139      ES/20Z.CM          12/18/2020    3632.750000          2020-12-11   \n",
       "2103140      ES/20Z.CM          12/18/2020    3632.750000          2020-12-11   \n",
       "2103141      NG/20Z.NX          11/25/2020       2.775000          2020-11-24   \n",
       "\n",
       "         ...  volume open_interest    1M    3M    6M   12M  fold     sigma  \\\n",
       "0        ...       2           413  1.50  1.51  1.53  1.44    -1  0.126342   \n",
       "1        ...       6            15  1.50  1.51  1.53  1.44    -1  0.022691   \n",
       "2        ...       7             8  1.50  1.51  1.53  1.44    -1  0.022691   \n",
       "3        ...      20           161  1.50  1.51  1.53  1.44    -1  0.022691   \n",
       "4        ...      13             7  1.50  1.51  1.53  1.44    -1  0.022691   \n",
       "...      ...     ...           ...   ...   ...   ...   ...   ...       ...   \n",
       "2103137  ...       3           223  0.08  0.09  0.10  0.09     4  0.022691   \n",
       "2103138  ...     134          6061  0.08  0.09  0.10  0.09     4  0.022691   \n",
       "2103139  ...      42           420  0.08  0.09  0.10  0.09     4  0.022691   \n",
       "2103140  ...      39           242  0.08  0.09  0.10  0.09     4  0.022691   \n",
       "2103141  ...       1           273  0.08  0.09  0.10  0.09     3  0.177440   \n",
       "\n",
       "              S_K      days  \n",
       "0        0.937866  0.093151  \n",
       "1        1.080086  0.326027  \n",
       "2        1.077017  0.326027  \n",
       "3        1.073949  0.326027  \n",
       "4        1.070881  0.326027  \n",
       "...           ...       ...  \n",
       "2103137  0.919414  0.046575  \n",
       "2103138  0.920790  0.046575  \n",
       "2103139  0.922166  0.046575  \n",
       "2103140  0.867112  0.046575  \n",
       "2103141  0.936937  0.000000  \n",
       "\n",
       "[2103142 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_C.reset_index(drop=True, inplace=True)\n",
    "data_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理 inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_C.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_C.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def xgb_model(data,nfold):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'eta': 0.01,\n",
    "        'random_state': CONFIG.seed,\n",
    "    }\n",
    "    scores = []\n",
    "    models = []\n",
    "    \n",
    "    for f in range(nfold):\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        train_idx = data[data.fold != f].index\n",
    "        val_idx = data[data.fold == f].index\n",
    "        min_max_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "        train_x = min_max_scaler.fit_transform(data.iloc[train_idx, :][features])\n",
    "        train_y = min_max_scaler.fit_transform(data.iloc[train_idx, :][target])\n",
    "        \n",
    "        val_x = min_max_scaler.fit_transform(data.iloc[val_idx, :][features])\n",
    "        val_y = min_max_scaler.fit_transform(data.iloc[val_idx, :][target])\n",
    "        if data.underlying.value_counts().shape[0] == 1:\n",
    "            run = wandb.init(project=\"Option-project\", entity=\"dylanli\", reinit=True, name=f'xgb_single_{f}')\n",
    "        else : \n",
    "            run = wandb.init(project=\"Option-project\", entity=\"dylanli\", reinit=True, name=f'xgb_multi_{f}')\n",
    "        \n",
    "        callback = wandb_callback()\n",
    "        \n",
    "        model = xgb.XGBRegressor()\n",
    "        model.set_params(**params)\n",
    "        model.fit(train_x, train_y, early_stopping_rounds=10, eval_set=[(val_x, val_y)], callbacks=[callback])\n",
    "        model.save_model(f'/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/model_xgb/model_{f}.json')\n",
    "        # plot\n",
    "        ax = xgb.plot_importance(model)\n",
    "        plt.show(ax)\n",
    "        wandb.log({\"chart\" : ax})\n",
    "\n",
    "        print(f\"{'='*20}{f} model trained{'='*20}\")\n",
    "        off_pred = model.predict(val_x, ntree_limit=model.best_ntree_limit)\n",
    "        off_score = np.sqrt(mean_squared_error(val_y, off_pred))\n",
    "        scores.append(off_score)\n",
    "        models.append(model)\n",
    "        print(f\"{'=' * 20} fold_{f} {'=' * 20}\")\n",
    "        print(f'rmse: {off_score}')\n",
    "        \n",
    "        \n",
    "        del train_x, train_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "        run.finish()\n",
    "    \n",
    "    return scores, models\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5z1fbzlv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afd9db4dde245dea88e457ffc8c785e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>█▇▆▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>142.46426</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_0</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/5z1fbzlv\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/5z1fbzlv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144235-5z1fbzlv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5z1fbzlv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_144356-2j1kywyx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/2j1kywyx\" target=\"_blank\">xgb_multi_0</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/qzgwttq17ps8lhfhrtgpdkx00000gn/T/ipykernel_78287/1921192065.py:27: UserWarning: wandb_callback will be deprecated in favor of WandbCallback. Please use WandbCallback for more features.\n",
      "  callback = wandb_callback()\n",
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
      "0\tvalidation_0-rmse:1.11542\n",
      "1\tvalidation_0-rmse:1.11291\n",
      "2\tvalidation_0-rmse:1.11056\n",
      "3\tvalidation_0-rmse:1.10831\n",
      "4\tvalidation_0-rmse:1.10613\n",
      "5\tvalidation_0-rmse:1.10411\n",
      "6\tvalidation_0-rmse:1.10214\n",
      "7\tvalidation_0-rmse:1.10028\n",
      "8\tvalidation_0-rmse:1.09858\n",
      "9\tvalidation_0-rmse:1.09682\n",
      "10\tvalidation_0-rmse:1.09534\n",
      "11\tvalidation_0-rmse:1.09379\n",
      "12\tvalidation_0-rmse:1.09237\n",
      "13\tvalidation_0-rmse:1.09108\n",
      "14\tvalidation_0-rmse:1.08987\n",
      "15\tvalidation_0-rmse:1.08863\n",
      "16\tvalidation_0-rmse:1.08753\n",
      "17\tvalidation_0-rmse:1.08644\n",
      "18\tvalidation_0-rmse:1.08557\n",
      "19\tvalidation_0-rmse:1.08463\n",
      "20\tvalidation_0-rmse:1.08393\n",
      "21\tvalidation_0-rmse:1.08330\n",
      "22\tvalidation_0-rmse:1.08258\n",
      "23\tvalidation_0-rmse:1.08204\n",
      "24\tvalidation_0-rmse:1.08147\n",
      "25\tvalidation_0-rmse:1.08098\n",
      "26\tvalidation_0-rmse:1.08073\n",
      "27\tvalidation_0-rmse:1.08054\n",
      "28\tvalidation_0-rmse:1.08041\n",
      "29\tvalidation_0-rmse:1.08031\n",
      "30\tvalidation_0-rmse:1.08014\n",
      "31\tvalidation_0-rmse:1.07998\n",
      "32\tvalidation_0-rmse:1.08013\n",
      "33\tvalidation_0-rmse:1.08011\n",
      "34\tvalidation_0-rmse:1.08040\n",
      "35\tvalidation_0-rmse:1.08044\n",
      "36\tvalidation_0-rmse:1.08059\n",
      "37\tvalidation_0-rmse:1.08101\n",
      "38\tvalidation_0-rmse:1.08150\n",
      "39\tvalidation_0-rmse:1.08198\n",
      "40\tvalidation_0-rmse:1.08255\n",
      "Stopping. Best iteration:\n",
      "[31]\tvalidation_0-rmse:1.07998\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================0 model trained====================\n",
      "==================== fold_0 ====================\n",
      "rmse: 1.0799835737971333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8e7fa8ea4e4b8ba1c84c019a3cecf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>1.08306</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_0</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/2j1kywyx\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/2j1kywyx</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144356-2j1kywyx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_144502-fb1fmfmo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/fb1fmfmo\" target=\"_blank\">xgb_multi_1</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/qzgwttq17ps8lhfhrtgpdkx00000gn/T/ipykernel_78287/1921192065.py:27: UserWarning:\n",
      "\n",
      "wandb_callback will be deprecated in favor of WandbCallback. Please use WandbCallback for more features.\n",
      "\n",
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning:\n",
      "\n",
      "Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
      "0\tvalidation_0-rmse:1.11506\n",
      "1\tvalidation_0-rmse:1.11215\n",
      "2\tvalidation_0-rmse:1.10932\n",
      "3\tvalidation_0-rmse:1.10659\n",
      "4\tvalidation_0-rmse:1.10391\n",
      "5\tvalidation_0-rmse:1.10128\n",
      "6\tvalidation_0-rmse:1.09861\n",
      "7\tvalidation_0-rmse:1.09619\n",
      "8\tvalidation_0-rmse:1.09380\n",
      "9\tvalidation_0-rmse:1.09140\n",
      "10\tvalidation_0-rmse:1.08924\n",
      "11\tvalidation_0-rmse:1.08705\n",
      "12\tvalidation_0-rmse:1.08484\n",
      "13\tvalidation_0-rmse:1.08282\n",
      "14\tvalidation_0-rmse:1.08083\n",
      "15\tvalidation_0-rmse:1.07878\n",
      "16\tvalidation_0-rmse:1.07690\n",
      "17\tvalidation_0-rmse:1.07512\n",
      "18\tvalidation_0-rmse:1.07328\n",
      "19\tvalidation_0-rmse:1.07155\n",
      "20\tvalidation_0-rmse:1.06989\n",
      "21\tvalidation_0-rmse:1.06831\n",
      "22\tvalidation_0-rmse:1.06669\n",
      "23\tvalidation_0-rmse:1.06515\n",
      "24\tvalidation_0-rmse:1.06369\n",
      "25\tvalidation_0-rmse:1.06230\n",
      "26\tvalidation_0-rmse:1.06091\n",
      "27\tvalidation_0-rmse:1.05956\n",
      "28\tvalidation_0-rmse:1.05828\n",
      "29\tvalidation_0-rmse:1.05716\n",
      "30\tvalidation_0-rmse:1.05601\n",
      "31\tvalidation_0-rmse:1.05479\n",
      "32\tvalidation_0-rmse:1.05367\n",
      "33\tvalidation_0-rmse:1.05267\n",
      "34\tvalidation_0-rmse:1.05167\n",
      "35\tvalidation_0-rmse:1.05073\n",
      "36\tvalidation_0-rmse:1.04978\n",
      "37\tvalidation_0-rmse:1.04884\n",
      "38\tvalidation_0-rmse:1.04801\n",
      "39\tvalidation_0-rmse:1.04720\n",
      "40\tvalidation_0-rmse:1.04645\n",
      "41\tvalidation_0-rmse:1.04569\n",
      "42\tvalidation_0-rmse:1.04495\n",
      "43\tvalidation_0-rmse:1.04424\n",
      "44\tvalidation_0-rmse:1.04359\n",
      "45\tvalidation_0-rmse:1.04299\n",
      "46\tvalidation_0-rmse:1.04244\n",
      "47\tvalidation_0-rmse:1.04198\n",
      "48\tvalidation_0-rmse:1.04145\n",
      "49\tvalidation_0-rmse:1.04104\n",
      "50\tvalidation_0-rmse:1.04063\n",
      "51\tvalidation_0-rmse:1.04028\n",
      "52\tvalidation_0-rmse:1.03996\n",
      "53\tvalidation_0-rmse:1.03966\n",
      "54\tvalidation_0-rmse:1.03930\n",
      "55\tvalidation_0-rmse:1.03904\n",
      "56\tvalidation_0-rmse:1.03881\n",
      "57\tvalidation_0-rmse:1.03857\n",
      "58\tvalidation_0-rmse:1.03847\n",
      "59\tvalidation_0-rmse:1.03831\n",
      "60\tvalidation_0-rmse:1.03808\n",
      "61\tvalidation_0-rmse:1.03801\n",
      "62\tvalidation_0-rmse:1.03785\n",
      "63\tvalidation_0-rmse:1.03782\n",
      "64\tvalidation_0-rmse:1.03787\n",
      "65\tvalidation_0-rmse:1.03784\n",
      "66\tvalidation_0-rmse:1.03788\n",
      "67\tvalidation_0-rmse:1.03795\n",
      "68\tvalidation_0-rmse:1.03805\n",
      "69\tvalidation_0-rmse:1.03796\n",
      "70\tvalidation_0-rmse:1.03801\n",
      "71\tvalidation_0-rmse:1.03817\n",
      "72\tvalidation_0-rmse:1.03828\n",
      "Stopping. Best iteration:\n",
      "[63]\tvalidation_0-rmse:1.03782\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================1 model trained====================\n",
      "==================== fold_1 ====================\n",
      "rmse: 1.037858707978806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254416d90b684d338866a93ec778d034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>██▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>1.03846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_1</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/fb1fmfmo\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/fb1fmfmo</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144502-fb1fmfmo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_144620-2c0nme2i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/2c0nme2i\" target=\"_blank\">xgb_multi_2</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/qzgwttq17ps8lhfhrtgpdkx00000gn/T/ipykernel_78287/1921192065.py:27: UserWarning:\n",
      "\n",
      "wandb_callback will be deprecated in favor of WandbCallback. Please use WandbCallback for more features.\n",
      "\n",
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning:\n",
      "\n",
      "Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
      "0\tvalidation_0-rmse:1.11478\n",
      "1\tvalidation_0-rmse:1.11159\n",
      "2\tvalidation_0-rmse:1.10848\n",
      "3\tvalidation_0-rmse:1.10543\n",
      "4\tvalidation_0-rmse:1.10245\n",
      "5\tvalidation_0-rmse:1.09954\n",
      "6\tvalidation_0-rmse:1.09676\n",
      "7\tvalidation_0-rmse:1.09398\n",
      "8\tvalidation_0-rmse:1.09133\n",
      "9\tvalidation_0-rmse:1.08867\n",
      "10\tvalidation_0-rmse:1.08620\n",
      "11\tvalidation_0-rmse:1.08379\n",
      "12\tvalidation_0-rmse:1.08143\n",
      "13\tvalidation_0-rmse:1.07912\n",
      "14\tvalidation_0-rmse:1.07688\n",
      "15\tvalidation_0-rmse:1.07469\n",
      "16\tvalidation_0-rmse:1.07255\n",
      "17\tvalidation_0-rmse:1.07047\n",
      "18\tvalidation_0-rmse:1.06844\n",
      "19\tvalidation_0-rmse:1.06646\n",
      "20\tvalidation_0-rmse:1.06453\n",
      "21\tvalidation_0-rmse:1.06264\n",
      "22\tvalidation_0-rmse:1.06081\n",
      "23\tvalidation_0-rmse:1.05902\n",
      "24\tvalidation_0-rmse:1.05727\n",
      "25\tvalidation_0-rmse:1.05549\n",
      "26\tvalidation_0-rmse:1.05384\n",
      "27\tvalidation_0-rmse:1.05225\n",
      "28\tvalidation_0-rmse:1.05068\n",
      "29\tvalidation_0-rmse:1.04917\n",
      "30\tvalidation_0-rmse:1.04770\n",
      "31\tvalidation_0-rmse:1.04625\n",
      "32\tvalidation_0-rmse:1.04486\n",
      "33\tvalidation_0-rmse:1.04350\n",
      "34\tvalidation_0-rmse:1.04219\n",
      "35\tvalidation_0-rmse:1.04087\n",
      "36\tvalidation_0-rmse:1.03962\n",
      "37\tvalidation_0-rmse:1.03842\n",
      "38\tvalidation_0-rmse:1.03725\n",
      "39\tvalidation_0-rmse:1.03611\n",
      "40\tvalidation_0-rmse:1.03500\n",
      "41\tvalidation_0-rmse:1.03394\n",
      "42\tvalidation_0-rmse:1.03290\n",
      "43\tvalidation_0-rmse:1.03191\n",
      "44\tvalidation_0-rmse:1.03093\n",
      "45\tvalidation_0-rmse:1.02999\n",
      "46\tvalidation_0-rmse:1.02907\n",
      "47\tvalidation_0-rmse:1.02819\n",
      "48\tvalidation_0-rmse:1.02734\n",
      "49\tvalidation_0-rmse:1.02650\n",
      "50\tvalidation_0-rmse:1.02571\n",
      "51\tvalidation_0-rmse:1.02493\n",
      "52\tvalidation_0-rmse:1.02415\n",
      "53\tvalidation_0-rmse:1.02343\n",
      "54\tvalidation_0-rmse:1.02273\n",
      "55\tvalidation_0-rmse:1.02206\n",
      "56\tvalidation_0-rmse:1.02140\n",
      "57\tvalidation_0-rmse:1.02078\n",
      "58\tvalidation_0-rmse:1.02017\n",
      "59\tvalidation_0-rmse:1.01960\n",
      "60\tvalidation_0-rmse:1.01905\n",
      "61\tvalidation_0-rmse:1.01850\n",
      "62\tvalidation_0-rmse:1.01799\n",
      "63\tvalidation_0-rmse:1.01749\n",
      "64\tvalidation_0-rmse:1.01701\n",
      "65\tvalidation_0-rmse:1.01656\n",
      "66\tvalidation_0-rmse:1.01611\n",
      "67\tvalidation_0-rmse:1.01569\n",
      "68\tvalidation_0-rmse:1.01529\n",
      "69\tvalidation_0-rmse:1.01487\n",
      "70\tvalidation_0-rmse:1.01449\n",
      "71\tvalidation_0-rmse:1.01415\n",
      "72\tvalidation_0-rmse:1.01381\n",
      "73\tvalidation_0-rmse:1.01349\n",
      "74\tvalidation_0-rmse:1.01319\n",
      "75\tvalidation_0-rmse:1.01290\n",
      "76\tvalidation_0-rmse:1.01262\n",
      "77\tvalidation_0-rmse:1.01236\n",
      "78\tvalidation_0-rmse:1.01209\n",
      "79\tvalidation_0-rmse:1.01185\n",
      "80\tvalidation_0-rmse:1.01162\n",
      "81\tvalidation_0-rmse:1.01142\n",
      "82\tvalidation_0-rmse:1.01123\n",
      "83\tvalidation_0-rmse:1.01104\n",
      "84\tvalidation_0-rmse:1.01088\n",
      "85\tvalidation_0-rmse:1.01070\n",
      "86\tvalidation_0-rmse:1.01053\n",
      "87\tvalidation_0-rmse:1.01037\n",
      "88\tvalidation_0-rmse:1.01026\n",
      "89\tvalidation_0-rmse:1.01014\n",
      "90\tvalidation_0-rmse:1.01000\n",
      "91\tvalidation_0-rmse:1.00988\n",
      "92\tvalidation_0-rmse:1.00977\n",
      "93\tvalidation_0-rmse:1.00968\n",
      "94\tvalidation_0-rmse:1.00958\n",
      "95\tvalidation_0-rmse:1.00950\n",
      "96\tvalidation_0-rmse:1.00944\n",
      "97\tvalidation_0-rmse:1.00940\n",
      "98\tvalidation_0-rmse:1.00935\n",
      "99\tvalidation_0-rmse:1.00930\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================2 model trained====================\n",
      "==================== fold_2 ====================\n",
      "rmse: 1.0093050711413805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9262c923183443b2a7da833dfac826c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.083453…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>██▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>1.0093</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_2</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/2c0nme2i\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/2c0nme2i</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144620-2c0nme2i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_144736-3k8e9utw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/3k8e9utw\" target=\"_blank\">xgb_multi_3</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/qzgwttq17ps8lhfhrtgpdkx00000gn/T/ipykernel_78287/1921192065.py:27: UserWarning:\n",
      "\n",
      "wandb_callback will be deprecated in favor of WandbCallback. Please use WandbCallback for more features.\n",
      "\n",
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning:\n",
      "\n",
      "Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
      "0\tvalidation_0-rmse:1.13625\n",
      "1\tvalidation_0-rmse:1.17914\n",
      "2\tvalidation_0-rmse:1.24363\n",
      "3\tvalidation_0-rmse:1.32609\n",
      "4\tvalidation_0-rmse:1.42296\n",
      "5\tvalidation_0-rmse:1.53110\n",
      "6\tvalidation_0-rmse:1.64791\n",
      "7\tvalidation_0-rmse:1.77136\n",
      "8\tvalidation_0-rmse:1.89984\n",
      "9\tvalidation_0-rmse:2.03210\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-rmse:1.13625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================3 model trained====================\n",
      "==================== fold_3 ====================\n",
      "rmse: 1.136250795784901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31d2c84ead34a1093fe8ada56891f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.083461…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>▁▁▂▂▃▄▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>2.16719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_3</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/3k8e9utw\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/3k8e9utw</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144736-3k8e9utw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_144834-31j1vqy0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/31j1vqy0\" target=\"_blank\">xgb_multi_4</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/qzgwttq17ps8lhfhrtgpdkx00000gn/T/ipykernel_78287/1921192065.py:27: UserWarning:\n",
      "\n",
      "wandb_callback will be deprecated in favor of WandbCallback. Please use WandbCallback for more features.\n",
      "\n",
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning:\n",
      "\n",
      "Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-rmse hasn't improved in 10 rounds.\n",
      "0\tvalidation_0-rmse:1.11776\n",
      "1\tvalidation_0-rmse:1.11782\n",
      "2\tvalidation_0-rmse:1.11819\n",
      "3\tvalidation_0-rmse:1.11888\n",
      "4\tvalidation_0-rmse:1.11986\n",
      "5\tvalidation_0-rmse:1.12113\n",
      "6\tvalidation_0-rmse:1.12264\n",
      "7\tvalidation_0-rmse:1.12451\n",
      "8\tvalidation_0-rmse:1.12647\n",
      "9\tvalidation_0-rmse:1.12885\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-rmse:1.11776\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================4 model trained====================\n",
      "==================== fold_4 ====================\n",
      "rmse: 1.1177624899871548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fd53f315204493bd1ef02e6bede05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.083566…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>▁▁▁▂▂▃▄▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_0-rmse</td><td>1.13131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">xgb_multi_4</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/31j1vqy0\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/31j1vqy0</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_144834-31j1vqy0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores, models = xgb_model(data_C, CONFIG.nfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### NN\n",
    "NN 的设计 \n",
    "- BatchNormalization\n",
    "- Dense \n",
    "- dense_block(x3)\n",
    "\n",
    "- batch_size = 128\n",
    "- epochs = 100\n",
    "- optimizer = Adam(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method' : 'bayes',\n",
    "    'metric' : {\n",
    "        'name' : 'rmse',\n",
    "        'goal' : 'minimize',\n",
    "    },\n",
    "    'parameters' : {\n",
    "        'epochs': {\n",
    "            'values' : [50, 100 ,200]\n",
    "        },\n",
    "        'dropout' : {\n",
    "            'values': [0.8, 0.6 , 0.5, 0.4]\n",
    "        },\n",
    "        'learning_rate' : {\n",
    "            'values': [0.01, 0.001, 0.003, 0.1]\n",
    "        },\n",
    "        'optimizer' : {\n",
    "            'values' : ['adam',  'sgd']\n",
    "        },\n",
    "        'activation' : {\n",
    "            'values' : ['relu', 'swish']\n",
    "        },\n",
    "        'nn_nodes': {\n",
    "            'values' : [[512,256],[256,128,64],[256,128,64],[256,64,16],[128,32], []]\n",
    "        }\n",
    "    },\n",
    "    'early_terminate' : {\n",
    "        'type' : 'hyperband',\n",
    "        'max_iter' : 10,\n",
    "        's' : 3\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: qoq1008c\n",
      "Sweep URL: https://wandb.ai/dylanli/Option-project/sweeps/qoq1008c\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new sweep\n",
    "# Arguments:\n",
    "#     – sweep_config: the sweep config dictionary defined above\n",
    "#     – entity: Set the username for the sweep\n",
    "#     – project: Set the project name for the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, entity=\"dylanli\", project=\"Option-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def nn_model(data=data_C, nfold=CONFIG.nfold,log=CONFIG.log_dir, is_sweep=True):\n",
    "    \n",
    "    config_defaults = {\n",
    "    'batch_size': 1024,\n",
    "    'epochs': 100,\n",
    "    'dropout': 0.5,\n",
    "    'activation_type': 'swish',\n",
    "    'optimizer': 'adam',\n",
    "    'seed': 42,\n",
    "    'learning_rate': 1e-3,\n",
    "    'nn_nodes' : [128, 128, 128],\n",
    "    }\n",
    "\n",
    "    if data.underlying.value_counts().shape[0] == 1:\n",
    "        run = wandb.init(config=config_defaults, project=\"Option-project\", entity=\"dylanli\", reinit=True, name=f'nn_single')\n",
    "    else : \n",
    "        run = wandb.init(config=config_defaults, project=\"Option-project\", entity=\"dylanli\", reinit=True, name=f'nn_multi')\n",
    "    \n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    # Deine the optimizer\n",
    "    if config.optimizer=='sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=config.learning_rate, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    elif config.optimizer=='adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "        \n",
    "    def dense_block(x, n_nodes, p=0.5, activation='swish'):\n",
    "        x = layers.Dropout(p)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dense(n_nodes, activation=activation)(x)\n",
    "        return x\n",
    "    \n",
    "    def get_nn(dense_blocks, optimizer, dropout):\n",
    "        input_ = layers.Input(shape=(len(features),))\n",
    "        x = layers.BatchNormalization()(input_)\n",
    "        x = layers.Dense(256, activation='swish')(x)\n",
    "        \n",
    "        #TODO 多层连接\n",
    "        if len(dense_blocks) >= 1:\n",
    "            p = dropout\n",
    "            for units in dense_blocks:\n",
    "                x = dense_block(x, units, p)\n",
    "                p -= 0.05\n",
    "            \n",
    "        output = layers.Dense(1)(x)\n",
    "        \n",
    "        model = keras.Model(input_, output)\n",
    "            \n",
    "        model.compile(optimizer, loss=tf.keras.losses.MeanAbsoluteError(name='val_loss'), metrics=[tf.keras.losses.MeanAbsoluteError(name='val_loss')])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    models = []\n",
    "    scores = []\n",
    "    for f in range(nfold):\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        train_idx = data[data.fold != f].index\n",
    "        val_idx = data[data.fold == f].index\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        \n",
    "        train_x = scaler.fit_transform(data.loc[train_idx, features])\n",
    "        train_y = scaler.fit_transform(np.array(data.loc[train_idx, ['settlement']]))\n",
    "        \n",
    "        val_x = scaler.fit_transform(data.loc[val_idx, features])\n",
    "        val_y = scaler.fit_transform(np.array(data.loc[val_idx, ['settlement']]))\n",
    "        \n",
    "        \n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(filepath=f'/Users/dylan/DylanLi/XJTLU/期权项目/Code/model_nn/model_nn_{f}.hdf5', save_best_only=True)\n",
    "        early_stop = keras.callbacks.EarlyStopping(patience=config.epochs//4)\n",
    "        tesnsorboard = keras.callbacks.TensorBoard(log, histogram_freq=1)\n",
    "        model = get_nn(config.nn_nodes, optimizer, config.dropout)\n",
    "        print(f\"{'=' * 20} fold_{f} Training {'=' * 20}\")\n",
    "        history = model.fit(train_x, train_y, epochs=config.epochs, batch_size=config.batch_size, validation_data=(val_x, val_y), callbacks=[checkpoint, early_stop, WandbCallback()], validation_freq=[1,1,1])\n",
    "        \n",
    "        pd.DataFrame(history.history, columns=['loss', 'val_loss']).plot()\n",
    "        plt.title(\"MSE\")\n",
    "        plt.show()\n",
    "        #loss, mae, mse = model.evaluate(val_x, val_y)\n",
    "        #print(f\"evaluation: loss: {loss}, mae: {mae}, mse: {mse}\")\n",
    "        \n",
    "        model.load_weights(f'/Users/dylan/DylanLi/XJTLU/期权项目/Code/model_nn/model_nn_{f}.hdf5')\n",
    "        off_pred = model.predict(val_x)\n",
    "        off_score = np.sqrt(mean_squared_error(val_y, off_pred))\n",
    "        #off_score = 0\n",
    "        \n",
    "        scores.append(off_score)\n",
    "        print(f\"{'=' * 20} fold_{f} score {'=' * 20}\")\n",
    "        print(f\"rmse: {off_score}\")\n",
    "        \n",
    "        del train_x, train_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "        run.finish()\n",
    "        break\n",
    "        \n",
    "    #wandb.log({\"Fold scores\": scores})\n",
    "    #return scores, models\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gz538n93 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: swish\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnn_nodes: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_153050-gz538n93</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/gz538n93\" target=\"_blank\">nn_multi</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dylanli/Option-project/sweeps/qoq1008c\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/sweeps/qoq1008c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== fold_0 Training ====================\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 15:31:04.160451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - ETA: 0s - loss: 0.2750 - val_loss: 0.2750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 15:31:17.207367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 14s 7ms/step - loss: 0.2750 - val_loss: 0.2900 - val_val_loss: 0.2900 - _timestamp: 1653291078.0000 - _runtime: 28.0000\n",
      "Epoch 2/200\n",
      "1850/1850 [==============================] - 12s 6ms/step - loss: 0.2740 - val_loss: 0.2740 - _timestamp: 1653291090.0000 - _runtime: 40.0000\n",
      "Epoch 3/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2738 - val_loss: 0.2738 - _timestamp: 1653291100.0000 - _runtime: 50.0000\n",
      "Epoch 4/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2739 - val_loss: 0.2739 - _timestamp: 1653291111.0000 - _runtime: 61.0000\n",
      "Epoch 5/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2690 - val_loss: 0.2690 - _timestamp: 1653291122.0000 - _runtime: 72.0000\n",
      "Epoch 6/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2634 - val_loss: 0.2634 - _timestamp: 1653291132.0000 - _runtime: 82.0000\n",
      "Epoch 7/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2608 - val_loss: 0.2608 - _timestamp: 1653291143.0000 - _runtime: 93.0000\n",
      "Epoch 8/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2598 - val_loss: 0.2598 - _timestamp: 1653291154.0000 - _runtime: 104.0000\n",
      "Epoch 9/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2596 - val_loss: 0.2596 - _timestamp: 1653291165.0000 - _runtime: 115.0000\n",
      "Epoch 10/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2592 - val_loss: 0.2592 - _timestamp: 1653291175.0000 - _runtime: 125.0000\n",
      "Epoch 11/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2591 - val_loss: 0.2591 - _timestamp: 1653291186.0000 - _runtime: 136.0000\n",
      "Epoch 12/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2590 - val_loss: 0.2590 - _timestamp: 1653291197.0000 - _runtime: 147.0000\n",
      "Epoch 13/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2586 - val_loss: 0.2586 - _timestamp: 1653291208.0000 - _runtime: 158.0000\n",
      "Epoch 14/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2582 - val_loss: 0.2582 - _timestamp: 1653291218.0000 - _runtime: 168.0000\n",
      "Epoch 15/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2579 - val_loss: 0.2579 - _timestamp: 1653291229.0000 - _runtime: 179.0000\n",
      "Epoch 16/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2574 - val_loss: 0.2574 - _timestamp: 1653291240.0000 - _runtime: 190.0000\n",
      "Epoch 17/200\n",
      "1282/1850 [===================>..........] - ETA: 3s - loss: 0.2567 - val_loss: 0.2567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (TransientError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2568 - val_loss: 0.2568 - _timestamp: 1653291251.0000 - _runtime: 201.0000\n",
      "Epoch 18/200\n",
      "1565/1850 [========================>.....] - ETA: 1s - loss: 0.2564 - val_loss: 0.2564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 170, in check_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 114, in communicate_stop_status\n",
      "    resp = self._communicate_stop_status(status)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 395, in _communicate_stop_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1850 [========================>.....] - ETA: 1s - loss: 0.2563 - val_loss: 0.2563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 152, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 125, in communicate_network_status\n",
      "    resp = self._communicate_network_status(status)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 405, in _communicate_network_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2565 - val_loss: 0.2565 - _timestamp: 1653291261.0000 - _runtime: 211.0000\n",
      "Epoch 19/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2563 - val_loss: 0.2563 - _timestamp: 1653291272.0000 - _runtime: 222.0000\n",
      "Epoch 20/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2564 - val_loss: 0.2564 - _timestamp: 1653291282.0000 - _runtime: 232.0000\n",
      "Epoch 21/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2560 - val_loss: 0.2560 - _timestamp: 1653291293.0000 - _runtime: 243.0000\n",
      "Epoch 22/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2558 - val_loss: 0.2558 - _timestamp: 1653291304.0000 - _runtime: 254.0000\n",
      "Epoch 23/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2557 - val_loss: 0.2557 - _timestamp: 1653291314.0000 - _runtime: 264.0000\n",
      "Epoch 24/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2556 - val_loss: 0.2556 - _timestamp: 1653291325.0000 - _runtime: 275.0000\n",
      "Epoch 25/200\n",
      " 310/1850 [====>.........................] - ETA: 9s - loss: 0.2539 - val_loss: 0.2539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2554 - val_loss: 0.2554 - _timestamp: 1653291336.0000 - _runtime: 286.0000\n",
      "Epoch 26/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2553 - val_loss: 0.2553 - _timestamp: 1653291346.0000 - _runtime: 296.0000\n",
      "Epoch 27/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2552 - val_loss: 0.2552 - _timestamp: 1653291357.0000 - _runtime: 307.0000\n",
      "Epoch 28/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2551 - val_loss: 0.2551 - _timestamp: 1653291368.0000 - _runtime: 318.0000\n",
      "Epoch 29/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2553 - val_loss: 0.2553 - _timestamp: 1653291378.0000 - _runtime: 328.0000\n",
      "Epoch 30/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2550 - val_loss: 0.2550 - _timestamp: 1653291389.0000 - _runtime: 339.0000\n",
      "Epoch 31/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2547 - val_loss: 0.2547 - _timestamp: 1653291400.0000 - _runtime: 350.0000\n",
      "Epoch 32/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2547 - val_loss: 0.2547 - _timestamp: 1653291410.0000 - _runtime: 360.0000\n",
      "Epoch 33/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2546 - val_loss: 0.2546 - _timestamp: 1653291421.0000 - _runtime: 371.0000\n",
      "Epoch 34/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2543 - val_loss: 0.2543 - _timestamp: 1653291432.0000 - _runtime: 382.0000\n",
      "Epoch 35/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2543 - val_loss: 0.2543 - _timestamp: 1653291442.0000 - _runtime: 392.0000\n",
      "Epoch 36/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2542 - val_loss: 0.2542 - _timestamp: 1653291453.0000 - _runtime: 403.0000\n",
      "Epoch 37/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2543 - val_loss: 0.2543 - _timestamp: 1653291463.0000 - _runtime: 413.0000\n",
      "Epoch 38/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2539 - val_loss: 0.2539 - _timestamp: 1653291474.0000 - _runtime: 424.0000\n",
      "Epoch 39/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2542 - val_loss: 0.2542 - _timestamp: 1653291484.0000 - _runtime: 434.0000\n",
      "Epoch 40/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2539 - val_loss: 0.2539 - _timestamp: 1653291495.0000 - _runtime: 445.0000\n",
      "Epoch 41/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2537 - val_loss: 0.2537 - _timestamp: 1653291505.0000 - _runtime: 455.0000\n",
      "Epoch 42/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2537 - val_loss: 0.2537 - _timestamp: 1653291516.0000 - _runtime: 466.0000\n",
      "Epoch 43/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2535 - val_loss: 0.2535 - _timestamp: 1653291527.0000 - _runtime: 477.0000\n",
      "Epoch 44/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2535 - val_loss: 0.2535 - _timestamp: 1653291537.0000 - _runtime: 487.0000\n",
      "Epoch 45/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2536 - val_loss: 0.2536 - _timestamp: 1653291548.0000 - _runtime: 498.0000\n",
      "Epoch 46/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2534 - val_loss: 0.2534 - _timestamp: 1653291558.0000 - _runtime: 508.0000\n",
      "Epoch 47/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2534 - val_loss: 0.2534 - _timestamp: 1653291569.0000 - _runtime: 519.0000\n",
      "Epoch 48/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2532 - val_loss: 0.2532 - _timestamp: 1653291580.0000 - _runtime: 530.0000\n",
      "Epoch 49/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2531 - val_loss: 0.2531 - _timestamp: 1653291591.0000 - _runtime: 541.0000\n",
      "Epoch 50/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2532 - val_loss: 0.2532 - _timestamp: 1653291601.0000 - _runtime: 551.0000\n",
      "Epoch 51/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2530 - val_loss: 0.2530 - _timestamp: 1653291612.0000 - _runtime: 562.0000\n",
      "Epoch 52/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2530 - val_loss: 0.2530 - _timestamp: 1653291622.0000 - _runtime: 572.0000\n",
      "Epoch 53/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2530 - val_loss: 0.2530 - _timestamp: 1653291633.0000 - _runtime: 583.0000\n",
      "Epoch 54/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2529 - val_loss: 0.2529 - _timestamp: 1653291644.0000 - _runtime: 594.0000\n",
      "Epoch 55/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2527 - val_loss: 0.2527 - _timestamp: 1653291654.0000 - _runtime: 604.0000\n",
      "Epoch 56/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2529 - val_loss: 0.2529 - _timestamp: 1653291665.0000 - _runtime: 615.0000\n",
      "Epoch 57/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2527 - val_loss: 0.2527 - _timestamp: 1653291676.0000 - _runtime: 626.0000\n",
      "Epoch 58/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2526 - val_loss: 0.2526 - _timestamp: 1653291686.0000 - _runtime: 636.0000\n",
      "Epoch 59/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2526 - val_loss: 0.2526 - _timestamp: 1653291697.0000 - _runtime: 647.0000\n",
      "Epoch 60/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2525 - val_loss: 0.2525 - _timestamp: 1653291708.0000 - _runtime: 658.0000\n",
      "Epoch 61/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2526 - val_loss: 0.2526 - _timestamp: 1653291718.0000 - _runtime: 668.0000\n",
      "Epoch 62/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2524 - val_loss: 0.2524 - _timestamp: 1653291729.0000 - _runtime: 679.0000\n",
      "Epoch 63/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2523 - val_loss: 0.2523 - _timestamp: 1653291739.0000 - _runtime: 689.0000\n",
      "Epoch 64/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2524 - val_loss: 0.2524 - _timestamp: 1653291750.0000 - _runtime: 700.0000\n",
      "Epoch 65/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2522 - val_loss: 0.2522 - _timestamp: 1653291760.0000 - _runtime: 710.0000\n",
      "Epoch 66/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2523 - val_loss: 0.2523 - _timestamp: 1653291771.0000 - _runtime: 721.0000\n",
      "Epoch 67/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2521 - val_loss: 0.2521 - _timestamp: 1653291782.0000 - _runtime: 732.0000\n",
      "Epoch 68/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2523 - val_loss: 0.2523 - _timestamp: 1653291792.0000 - _runtime: 742.0000\n",
      "Epoch 69/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2523 - val_loss: 0.2523 - _timestamp: 1653291803.0000 - _runtime: 753.0000\n",
      "Epoch 70/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2519 - val_loss: 0.2519 - _timestamp: 1653291814.0000 - _runtime: 764.0000\n",
      "Epoch 71/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2520 - val_loss: 0.2520 - _timestamp: 1653291824.0000 - _runtime: 774.0000\n",
      "Epoch 72/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2519 - val_loss: 0.2519 - _timestamp: 1653291835.0000 - _runtime: 785.0000\n",
      "Epoch 73/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2519 - val_loss: 0.2519 - _timestamp: 1653291846.0000 - _runtime: 796.0000\n",
      "Epoch 74/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2518 - val_loss: 0.2518 - _timestamp: 1653291856.0000 - _runtime: 806.0000\n",
      "Epoch 75/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2516 - val_loss: 0.2516 - _timestamp: 1653291867.0000 - _runtime: 817.0000\n",
      "Epoch 76/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2518 - val_loss: 0.2518 - _timestamp: 1653291877.0000 - _runtime: 827.0000\n",
      "Epoch 77/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2517 - val_loss: 0.2517 - _timestamp: 1653291888.0000 - _runtime: 838.0000\n",
      "Epoch 78/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2519 - val_loss: 0.2519 - _timestamp: 1653291898.0000 - _runtime: 848.0000\n",
      "Epoch 79/200\n",
      "1454/1850 [======================>.......] - ETA: 2s - loss: 0.2520 - val_loss: 0.2520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ProxyError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2515 - val_loss: 0.2515 - _timestamp: 1653291909.0000 - _runtime: 859.0000\n",
      "Epoch 80/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2516 - val_loss: 0.2516 - _timestamp: 1653291920.0000 - _runtime: 870.0000\n",
      "Epoch 81/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2516 - val_loss: 0.2516 - _timestamp: 1653291930.0000 - _runtime: 880.0000\n",
      "Epoch 82/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2516 - val_loss: 0.2516 - _timestamp: 1653291941.0000 - _runtime: 891.0000\n",
      "Epoch 83/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2513 - val_loss: 0.2513 - _timestamp: 1653291952.0000 - _runtime: 902.0000\n",
      "Epoch 84/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2515 - val_loss: 0.2515 - _timestamp: 1653291962.0000 - _runtime: 912.0000\n",
      "Epoch 85/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2513 - val_loss: 0.2513 - _timestamp: 1653291973.0000 - _runtime: 923.0000\n",
      "Epoch 86/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2513 - val_loss: 0.2513 - _timestamp: 1653291983.0000 - _runtime: 933.0000\n",
      "Epoch 87/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2513 - val_loss: 0.2513 - _timestamp: 1653291994.0000 - _runtime: 944.0000\n",
      "Epoch 88/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2511 - val_loss: 0.2511 - _timestamp: 1653292004.0000 - _runtime: 954.0000\n",
      "Epoch 89/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2512 - val_loss: 0.2512 - _timestamp: 1653292015.0000 - _runtime: 965.0000\n",
      "Epoch 90/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2511 - val_loss: 0.2511 - _timestamp: 1653292026.0000 - _runtime: 976.0000\n",
      "Epoch 91/200\n",
      "1111/1850 [=================>............] - ETA: 4s - loss: 0.2508 - val_loss: 0.2508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2510 - val_loss: 0.2510 - _timestamp: 1653292036.0000 - _runtime: 986.0000\n",
      "Epoch 92/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2511 - val_loss: 0.2511 - _timestamp: 1653292047.0000 - _runtime: 997.0000\n",
      "Epoch 93/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2511 - val_loss: 0.2511 - _timestamp: 1653292057.0000 - _runtime: 1007.0000\n",
      "Epoch 94/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2509 - val_loss: 0.2509 - _timestamp: 1653292068.0000 - _runtime: 1018.0000\n",
      "Epoch 95/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2508 - val_loss: 0.2508 - _timestamp: 1653292078.0000 - _runtime: 1028.0000\n",
      "Epoch 96/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2509 - val_loss: 0.2509 - _timestamp: 1653292089.0000 - _runtime: 1039.0000\n",
      "Epoch 97/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2508 - val_loss: 0.2508 - _timestamp: 1653292100.0000 - _runtime: 1050.0000\n",
      "Epoch 98/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2509 - val_loss: 0.2509 - _timestamp: 1653292110.0000 - _runtime: 1060.0000\n",
      "Epoch 99/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653292121.0000 - _runtime: 1071.0000\n",
      "Epoch 100/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2508 - val_loss: 0.2508 - _timestamp: 1653292132.0000 - _runtime: 1082.0000\n",
      "Epoch 101/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653292142.0000 - _runtime: 1092.0000\n",
      "Epoch 102/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653292153.0000 - _runtime: 1103.0000\n",
      "Epoch 103/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653292163.0000 - _runtime: 1113.0000\n",
      "Epoch 104/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2508 - val_loss: 0.2508 - _timestamp: 1653292174.0000 - _runtime: 1124.0000\n",
      "Epoch 105/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653292184.0000 - _runtime: 1134.0000\n",
      "Epoch 106/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653292195.0000 - _runtime: 1145.0000\n",
      "Epoch 107/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653292205.0000 - _runtime: 1155.0000\n",
      "Epoch 108/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653292216.0000 - _runtime: 1166.0000\n",
      "Epoch 109/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2504 - val_loss: 0.2504 - _timestamp: 1653292227.0000 - _runtime: 1177.0000\n",
      "Epoch 110/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2503 - val_loss: 0.2503 - _timestamp: 1653292238.0000 - _runtime: 1188.0000\n",
      "Epoch 111/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2503 - val_loss: 0.2503 - _timestamp: 1653292249.0000 - _runtime: 1199.0000\n",
      "Epoch 112/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653292259.0000 - _runtime: 1209.0000\n",
      "Epoch 113/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653292270.0000 - _runtime: 1220.0000\n",
      "Epoch 114/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2504 - val_loss: 0.2504 - _timestamp: 1653292281.0000 - _runtime: 1231.0000\n",
      "Epoch 115/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2503 - val_loss: 0.2503 - _timestamp: 1653292291.0000 - _runtime: 1241.0000\n",
      "Epoch 116/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653292302.0000 - _runtime: 1252.0000\n",
      "Epoch 117/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653292313.0000 - _runtime: 1263.0000\n",
      "Epoch 118/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653292323.0000 - _runtime: 1273.0000\n",
      "Epoch 119/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2500 - val_loss: 0.2500 - _timestamp: 1653292334.0000 - _runtime: 1284.0000\n",
      "Epoch 120/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2501 - val_loss: 0.2501 - _timestamp: 1653292345.0000 - _runtime: 1295.0000\n",
      "Epoch 121/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653292355.0000 - _runtime: 1305.0000\n",
      "Epoch 122/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653292366.0000 - _runtime: 1316.0000\n",
      "Epoch 123/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2499 - val_loss: 0.2499 - _timestamp: 1653292377.0000 - _runtime: 1327.0000\n",
      "Epoch 124/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2500 - val_loss: 0.2500 - _timestamp: 1653292387.0000 - _runtime: 1337.0000\n",
      "Epoch 125/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2500 - val_loss: 0.2500 - _timestamp: 1653292398.0000 - _runtime: 1348.0000\n",
      "Epoch 126/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2499 - val_loss: 0.2499 - _timestamp: 1653292409.0000 - _runtime: 1359.0000\n",
      "Epoch 127/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2501 - val_loss: 0.2501 - _timestamp: 1653292419.0000 - _runtime: 1369.0000\n",
      "Epoch 128/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2500 - val_loss: 0.2500 - _timestamp: 1653292430.0000 - _runtime: 1380.0000\n",
      "Epoch 129/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292441.0000 - _runtime: 1391.0000\n",
      "Epoch 130/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2499 - val_loss: 0.2499 - _timestamp: 1653292452.0000 - _runtime: 1402.0000\n",
      "Epoch 131/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653292462.0000 - _runtime: 1412.0000\n",
      "Epoch 132/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2495 - val_loss: 0.2495 - _timestamp: 1653292473.0000 - _runtime: 1423.0000\n",
      "Epoch 133/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2497 - val_loss: 0.2497 - _timestamp: 1653292484.0000 - _runtime: 1434.0000\n",
      "Epoch 134/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2495 - val_loss: 0.2495 - _timestamp: 1653292494.0000 - _runtime: 1444.0000\n",
      "Epoch 135/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292505.0000 - _runtime: 1455.0000\n",
      "Epoch 136/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653292516.0000 - _runtime: 1466.0000\n",
      "Epoch 137/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653292526.0000 - _runtime: 1476.0000\n",
      "Epoch 138/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653292537.0000 - _runtime: 1487.0000\n",
      "Epoch 139/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2497 - val_loss: 0.2497 - _timestamp: 1653292548.0000 - _runtime: 1498.0000\n",
      "Epoch 140/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292558.0000 - _runtime: 1508.0000\n",
      "Epoch 141/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653292569.0000 - _runtime: 1519.0000\n",
      "Epoch 142/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292580.0000 - _runtime: 1530.0000\n",
      "Epoch 143/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292590.0000 - _runtime: 1540.0000\n",
      "Epoch 144/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292601.0000 - _runtime: 1551.0000\n",
      "Epoch 145/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292612.0000 - _runtime: 1562.0000\n",
      "Epoch 146/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2495 - val_loss: 0.2495 - _timestamp: 1653292622.0000 - _runtime: 1572.0000\n",
      "Epoch 147/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292633.0000 - _runtime: 1583.0000\n",
      "Epoch 148/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653292644.0000 - _runtime: 1594.0000\n",
      "Epoch 149/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292654.0000 - _runtime: 1604.0000\n",
      "Epoch 150/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653292665.0000 - _runtime: 1615.0000\n",
      "Epoch 151/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292676.0000 - _runtime: 1626.0000\n",
      "Epoch 152/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653292686.0000 - _runtime: 1636.0000\n",
      "Epoch 153/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2492 - val_loss: 0.2492 - _timestamp: 1653292697.0000 - _runtime: 1647.0000\n",
      "Epoch 154/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292708.0000 - _runtime: 1658.0000\n",
      "Epoch 155/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2495 - val_loss: 0.2495 - _timestamp: 1653292718.0000 - _runtime: 1668.0000\n",
      "Epoch 156/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292729.0000 - _runtime: 1679.0000\n",
      "Epoch 157/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653292740.0000 - _runtime: 1690.0000\n",
      "Epoch 158/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292750.0000 - _runtime: 1700.0000\n",
      "Epoch 159/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292761.0000 - _runtime: 1711.0000\n",
      "Epoch 160/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2492 - val_loss: 0.2492 - _timestamp: 1653292772.0000 - _runtime: 1722.0000\n",
      "Epoch 161/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2492 - val_loss: 0.2492 - _timestamp: 1653292782.0000 - _runtime: 1732.0000\n",
      "Epoch 162/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292793.0000 - _runtime: 1743.0000\n",
      "Epoch 163/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292804.0000 - _runtime: 1754.0000\n",
      "Epoch 164/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292815.0000 - _runtime: 1765.0000\n",
      "Epoch 165/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292826.0000 - _runtime: 1776.0000\n",
      "Epoch 166/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292837.0000 - _runtime: 1787.0000\n",
      "Epoch 167/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292847.0000 - _runtime: 1797.0000\n",
      "Epoch 168/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292858.0000 - _runtime: 1808.0000\n",
      "Epoch 169/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292869.0000 - _runtime: 1819.0000\n",
      "Epoch 170/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292879.0000 - _runtime: 1829.0000\n",
      "Epoch 171/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653292890.0000 - _runtime: 1840.0000\n",
      "Epoch 172/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292901.0000 - _runtime: 1851.0000\n",
      "Epoch 173/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292911.0000 - _runtime: 1861.0000\n",
      "Epoch 174/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653292922.0000 - _runtime: 1872.0000\n",
      "Epoch 175/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653292933.0000 - _runtime: 1883.0000\n",
      "Epoch 176/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653292944.0000 - _runtime: 1894.0000\n",
      "Epoch 177/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653292954.0000 - _runtime: 1904.0000\n",
      "Epoch 178/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653292965.0000 - _runtime: 1915.0000\n",
      "Epoch 179/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653292976.0000 - _runtime: 1926.0000\n",
      "Epoch 180/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653292986.0000 - _runtime: 1936.0000\n",
      "Epoch 181/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653292997.0000 - _runtime: 1947.0000\n",
      "Epoch 182/200\n",
      "1220/1850 [==================>...........] - ETA: 3s - loss: 0.2490 - val_loss: 0.2490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ProxyError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653293008.0000 - _runtime: 1958.0000\n",
      "Epoch 183/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653293018.0000 - _runtime: 1968.0000\n",
      "Epoch 184/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653293029.0000 - _runtime: 1979.0000\n",
      "Epoch 185/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653293039.0000 - _runtime: 1989.0000\n",
      "Epoch 186/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293050.0000 - _runtime: 2000.0000\n",
      "Epoch 187/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653293061.0000 - _runtime: 2011.0000\n",
      "Epoch 188/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293071.0000 - _runtime: 2021.0000\n",
      "Epoch 189/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2486 - val_loss: 0.2486 - _timestamp: 1653293082.0000 - _runtime: 2032.0000\n",
      "Epoch 190/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2490 - val_loss: 0.2490 - _timestamp: 1653293092.0000 - _runtime: 2042.0000\n",
      "Epoch 191/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653293103.0000 - _runtime: 2053.0000\n",
      "Epoch 192/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293113.0000 - _runtime: 2063.0000\n",
      "Epoch 193/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293124.0000 - _runtime: 2074.0000\n",
      "Epoch 194/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293135.0000 - _runtime: 2085.0000\n",
      "Epoch 195/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653293145.0000 - _runtime: 2095.0000\n",
      "Epoch 196/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653293156.0000 - _runtime: 2106.0000\n",
      "Epoch 197/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2486 - val_loss: 0.2486 - _timestamp: 1653293167.0000 - _runtime: 2117.0000\n",
      "Epoch 198/200\n",
      "1090/1850 [================>.............] - ETA: 4s - loss: 0.2481 - val_loss: 0.2481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ProxyError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2484 - val_loss: 0.2484 - _timestamp: 1653293177.0000 - _runtime: 2127.0000\n",
      "Epoch 199/200\n",
      "1850/1850 [==============================] - 11s 6ms/step - loss: 0.2485 - val_loss: 0.2485 - _timestamp: 1653293188.0000 - _runtime: 2138.0000\n",
      "Epoch 200/200\n",
      "1850/1850 [==============================] - 10s 6ms/step - loss: 0.2485 - val_loss: 0.2485 - _timestamp: 1653293198.0000 - _runtime: 2148.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:06:39.010474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== fold_0 score ====================\n",
      "rmse: 1.0124367721760243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd86571e6d3e4db88dfe2ae06ff633bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.045 MB of 0.045 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>197</td></tr><tr><td>best_val_loss</td><td>0.24843</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>loss</td><td>0.24852</td></tr><tr><td>val_loss</td><td>0.24852</td></tr><tr><td>val_val_loss</td><td>0.29003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">nn_multi</strong>: <a href=\"https://wandb.ai/dylanli/Option-project/runs/gz538n93\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/runs/gz538n93</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220523_153050-gz538n93/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aq9eawdy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnn_nodes: [512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylanli\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dylan/iCollections/桌面文件/Repo/Option_Pricing/Code/wandb/run-20220523_160802-aq9eawdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dylanli/Option-project/runs/aq9eawdy\" target=\"_blank\">nn_multi</a></strong> to <a href=\"https://wandb.ai/dylanli/Option-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dylanli/Option-project/sweeps/qoq1008c\" target=\"_blank\">https://wandb.ai/dylanli/Option-project/sweeps/qoq1008c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== fold_0 Training ====================\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:08:13.492064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - ETA: 0s - loss: 0.3198 - val_loss: 0.3198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:08:36.183925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 25s 12ms/step - loss: 0.3198 - val_loss: 0.2890 - val_val_loss: 0.2890 - _timestamp: 1653293317.0000 - _runtime: 35.0000\n",
      "Epoch 2/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2727 - val_loss: 0.2727 - _timestamp: 1653293339.0000 - _runtime: 57.0000\n",
      "Epoch 3/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2726 - val_loss: 0.2726 - _timestamp: 1653293360.0000 - _runtime: 78.0000\n",
      "Epoch 4/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2725 - val_loss: 0.2725 - _timestamp: 1653293381.0000 - _runtime: 99.0000\n",
      "Epoch 5/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2721 - val_loss: 0.2721 - _timestamp: 1653293403.0000 - _runtime: 121.0000\n",
      "Epoch 6/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2716 - val_loss: 0.2716 - _timestamp: 1653293424.0000 - _runtime: 142.0000\n",
      "Epoch 7/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2711 - val_loss: 0.2711 - _timestamp: 1653293445.0000 - _runtime: 163.0000\n",
      "Epoch 8/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2706 - val_loss: 0.2706 - _timestamp: 1653293467.0000 - _runtime: 185.0000\n",
      "Epoch 9/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2702 - val_loss: 0.2702 - _timestamp: 1653293488.0000 - _runtime: 206.0000\n",
      "Epoch 10/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2698 - val_loss: 0.2698 - _timestamp: 1653293509.0000 - _runtime: 227.0000\n",
      "Epoch 11/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2694 - val_loss: 0.2694 - _timestamp: 1653293531.0000 - _runtime: 249.0000\n",
      "Epoch 12/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2690 - val_loss: 0.2690 - _timestamp: 1653293553.0000 - _runtime: 271.0000\n",
      "Epoch 13/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2686 - val_loss: 0.2686 - _timestamp: 1653293573.0000 - _runtime: 291.0000\n",
      "Epoch 14/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2682 - val_loss: 0.2682 - _timestamp: 1653293595.0000 - _runtime: 313.0000\n",
      "Epoch 15/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2679 - val_loss: 0.2679 - _timestamp: 1653293616.0000 - _runtime: 334.0000\n",
      "Epoch 16/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2676 - val_loss: 0.2676 - _timestamp: 1653293637.0000 - _runtime: 355.0000\n",
      "Epoch 17/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2673 - val_loss: 0.2673 - _timestamp: 1653293658.0000 - _runtime: 376.0000\n",
      "Epoch 18/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2669 - val_loss: 0.2669 - _timestamp: 1653293680.0000 - _runtime: 398.0000\n",
      "Epoch 19/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2667 - val_loss: 0.2667 - _timestamp: 1653293701.0000 - _runtime: 419.0000\n",
      "Epoch 20/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2663 - val_loss: 0.2663 - _timestamp: 1653293722.0000 - _runtime: 440.0000\n",
      "Epoch 21/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2660 - val_loss: 0.2660 - _timestamp: 1653293744.0000 - _runtime: 462.0000\n",
      "Epoch 22/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2658 - val_loss: 0.2658 - _timestamp: 1653293765.0000 - _runtime: 483.0000\n",
      "Epoch 23/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2655 - val_loss: 0.2655 - _timestamp: 1653293786.0000 - _runtime: 504.0000\n",
      "Epoch 24/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2651 - val_loss: 0.2651 - _timestamp: 1653293807.0000 - _runtime: 525.0000\n",
      "Epoch 25/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2649 - val_loss: 0.2649 - _timestamp: 1653293829.0000 - _runtime: 547.0000\n",
      "Epoch 26/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2646 - val_loss: 0.2646 - _timestamp: 1653293850.0000 - _runtime: 568.0000\n",
      "Epoch 27/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2643 - val_loss: 0.2643 - _timestamp: 1653293872.0000 - _runtime: 590.0000\n",
      "Epoch 28/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2640 - val_loss: 0.2640 - _timestamp: 1653293893.0000 - _runtime: 611.0000\n",
      "Epoch 29/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2637 - val_loss: 0.2637 - _timestamp: 1653293914.0000 - _runtime: 632.0000\n",
      "Epoch 30/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2634 - val_loss: 0.2634 - _timestamp: 1653293935.0000 - _runtime: 653.0000\n",
      "Epoch 31/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2630 - val_loss: 0.2630 - _timestamp: 1653293957.0000 - _runtime: 675.0000\n",
      "Epoch 32/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2627 - val_loss: 0.2627 - _timestamp: 1653293978.0000 - _runtime: 696.0000\n",
      "Epoch 33/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2623 - val_loss: 0.2623 - _timestamp: 1653293999.0000 - _runtime: 717.0000\n",
      "Epoch 34/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2620 - val_loss: 0.2620 - _timestamp: 1653294021.0000 - _runtime: 739.0000\n",
      "Epoch 35/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2616 - val_loss: 0.2616 - _timestamp: 1653294042.0000 - _runtime: 760.0000\n",
      "Epoch 36/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2612 - val_loss: 0.2612 - _timestamp: 1653294063.0000 - _runtime: 781.0000\n",
      "Epoch 37/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2609 - val_loss: 0.2609 - _timestamp: 1653294085.0000 - _runtime: 803.0000\n",
      "Epoch 38/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2606 - val_loss: 0.2606 - _timestamp: 1653294107.0000 - _runtime: 825.0000\n",
      "Epoch 39/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2602 - val_loss: 0.2602 - _timestamp: 1653294128.0000 - _runtime: 846.0000\n",
      "Epoch 40/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2599 - val_loss: 0.2599 - _timestamp: 1653294149.0000 - _runtime: 867.0000\n",
      "Epoch 41/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2596 - val_loss: 0.2596 - _timestamp: 1653294171.0000 - _runtime: 889.0000\n",
      "Epoch 42/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2591 - val_loss: 0.2591 - _timestamp: 1653294192.0000 - _runtime: 910.0000\n",
      "Epoch 43/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2589 - val_loss: 0.2589 - _timestamp: 1653294213.0000 - _runtime: 931.0000\n",
      "Epoch 44/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2587 - val_loss: 0.2587 - _timestamp: 1653294235.0000 - _runtime: 953.0000\n",
      "Epoch 45/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2583 - val_loss: 0.2583 - _timestamp: 1653294256.0000 - _runtime: 974.0000\n",
      "Epoch 46/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2580 - val_loss: 0.2580 - _timestamp: 1653294277.0000 - _runtime: 995.0000\n",
      "Epoch 47/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2577 - val_loss: 0.2577 - _timestamp: 1653294299.0000 - _runtime: 1017.0000\n",
      "Epoch 48/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2574 - val_loss: 0.2574 - _timestamp: 1653294320.0000 - _runtime: 1038.0000\n",
      "Epoch 49/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2570 - val_loss: 0.2570 - _timestamp: 1653294341.0000 - _runtime: 1059.0000\n",
      "Epoch 50/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2567 - val_loss: 0.2567 - _timestamp: 1653294363.0000 - _runtime: 1081.0000\n",
      "Epoch 51/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2565 - val_loss: 0.2565 - _timestamp: 1653294384.0000 - _runtime: 1102.0000\n",
      "Epoch 52/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2563 - val_loss: 0.2563 - _timestamp: 1653294405.0000 - _runtime: 1123.0000\n",
      "Epoch 53/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2559 - val_loss: 0.2559 - _timestamp: 1653294427.0000 - _runtime: 1145.0000\n",
      "Epoch 54/200\n",
      "1850/1850 [==============================] - 21s 12ms/step - loss: 0.2557 - val_loss: 0.2557 - _timestamp: 1653294448.0000 - _runtime: 1166.0000\n",
      "Epoch 55/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2555 - val_loss: 0.2555 - _timestamp: 1653294469.0000 - _runtime: 1187.0000\n",
      "Epoch 56/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2552 - val_loss: 0.2552 - _timestamp: 1653294491.0000 - _runtime: 1209.0000\n",
      "Epoch 57/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2549 - val_loss: 0.2549 - _timestamp: 1653294512.0000 - _runtime: 1230.0000\n",
      "Epoch 58/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2547 - val_loss: 0.2547 - _timestamp: 1653294533.0000 - _runtime: 1251.0000\n",
      "Epoch 59/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2545 - val_loss: 0.2545 - _timestamp: 1653294553.0000 - _runtime: 1271.0000\n",
      "Epoch 60/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2542 - val_loss: 0.2542 - _timestamp: 1653294572.0000 - _runtime: 1290.0000\n",
      "Epoch 61/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2540 - val_loss: 0.2540 - _timestamp: 1653294592.0000 - _runtime: 1310.0000\n",
      "Epoch 62/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2539 - val_loss: 0.2539 - _timestamp: 1653294612.0000 - _runtime: 1330.0000\n",
      "Epoch 63/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2537 - val_loss: 0.2537 - _timestamp: 1653294633.0000 - _runtime: 1351.0000\n",
      "Epoch 64/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2534 - val_loss: 0.2534 - _timestamp: 1653294653.0000 - _runtime: 1371.0000\n",
      "Epoch 65/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2532 - val_loss: 0.2532 - _timestamp: 1653294673.0000 - _runtime: 1391.0000\n",
      "Epoch 66/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2531 - val_loss: 0.2531 - _timestamp: 1653294693.0000 - _runtime: 1411.0000\n",
      "Epoch 67/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2528 - val_loss: 0.2528 - _timestamp: 1653294713.0000 - _runtime: 1431.0000\n",
      "Epoch 68/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2528 - val_loss: 0.2528 - _timestamp: 1653294733.0000 - _runtime: 1451.0000\n",
      "Epoch 69/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2526 - val_loss: 0.2526 - _timestamp: 1653294753.0000 - _runtime: 1471.0000\n",
      "Epoch 70/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2524 - val_loss: 0.2524 - _timestamp: 1653294773.0000 - _runtime: 1491.0000\n",
      "Epoch 71/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2523 - val_loss: 0.2523 - _timestamp: 1653294793.0000 - _runtime: 1511.0000\n",
      "Epoch 72/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2519 - val_loss: 0.2519 - _timestamp: 1653294813.0000 - _runtime: 1531.0000\n",
      "Epoch 73/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2520 - val_loss: 0.2520 - _timestamp: 1653294833.0000 - _runtime: 1551.0000\n",
      "Epoch 74/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2518 - val_loss: 0.2518 - _timestamp: 1653294853.0000 - _runtime: 1571.0000\n",
      "Epoch 75/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2517 - val_loss: 0.2517 - _timestamp: 1653294873.0000 - _runtime: 1591.0000\n",
      "Epoch 76/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2515 - val_loss: 0.2515 - _timestamp: 1653294893.0000 - _runtime: 1611.0000\n",
      "Epoch 77/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2514 - val_loss: 0.2514 - _timestamp: 1653294913.0000 - _runtime: 1631.0000\n",
      "Epoch 78/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2513 - val_loss: 0.2513 - _timestamp: 1653294933.0000 - _runtime: 1651.0000\n",
      "Epoch 79/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2512 - val_loss: 0.2512 - _timestamp: 1653294953.0000 - _runtime: 1671.0000\n",
      "Epoch 80/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2511 - val_loss: 0.2511 - _timestamp: 1653294974.0000 - _runtime: 1692.0000\n",
      "Epoch 81/200\n",
      " 120/1850 [>.............................] - ETA: 19s - loss: 0.2452 - val_loss: 0.2452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2509 - val_loss: 0.2509 - _timestamp: 1653294994.0000 - _runtime: 1712.0000\n",
      "Epoch 82/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2507 - val_loss: 0.2507 - _timestamp: 1653295014.0000 - _runtime: 1732.0000\n",
      "Epoch 83/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2506 - val_loss: 0.2506 - _timestamp: 1653295034.0000 - _runtime: 1752.0000\n",
      "Epoch 84/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653295054.0000 - _runtime: 1772.0000\n",
      "Epoch 85/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2505 - val_loss: 0.2505 - _timestamp: 1653295074.0000 - _runtime: 1792.0000\n",
      "Epoch 86/200\n",
      "1850/1850 [==============================] - 22s 12ms/step - loss: 0.2504 - val_loss: 0.2504 - _timestamp: 1653295096.0000 - _runtime: 1814.0000\n",
      "Epoch 87/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653295116.0000 - _runtime: 1834.0000\n",
      "Epoch 88/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2502 - val_loss: 0.2502 - _timestamp: 1653295136.0000 - _runtime: 1854.0000\n",
      "Epoch 89/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2500 - val_loss: 0.2500 - _timestamp: 1653295156.0000 - _runtime: 1874.0000\n",
      "Epoch 90/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2498 - val_loss: 0.2498 - _timestamp: 1653295177.0000 - _runtime: 1895.0000\n",
      "Epoch 91/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2497 - val_loss: 0.2497 - _timestamp: 1653295197.0000 - _runtime: 1915.0000\n",
      "Epoch 92/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2497 - val_loss: 0.2497 - _timestamp: 1653295218.0000 - _runtime: 1936.0000\n",
      "Epoch 93/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2496 - val_loss: 0.2496 - _timestamp: 1653295238.0000 - _runtime: 1956.0000\n",
      "Epoch 94/200\n",
      "1850/1850 [==============================] - 21s 11ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653295259.0000 - _runtime: 1977.0000\n",
      "Epoch 95/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653295279.0000 - _runtime: 1997.0000\n",
      "Epoch 96/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2494 - val_loss: 0.2494 - _timestamp: 1653295299.0000 - _runtime: 2017.0000\n",
      "Epoch 97/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2493 - val_loss: 0.2493 - _timestamp: 1653295318.0000 - _runtime: 2036.0000\n",
      "Epoch 98/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653295339.0000 - _runtime: 2057.0000\n",
      "Epoch 99/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2491 - val_loss: 0.2491 - _timestamp: 1653295359.0000 - _runtime: 2077.0000\n",
      "Epoch 100/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2489 - val_loss: 0.2489 - _timestamp: 1653295378.0000 - _runtime: 2096.0000\n",
      "Epoch 101/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2488 - val_loss: 0.2488 - _timestamp: 1653295398.0000 - _runtime: 2116.0000\n",
      "Epoch 102/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2487 - val_loss: 0.2487 - _timestamp: 1653295418.0000 - _runtime: 2136.0000\n",
      "Epoch 103/200\n",
      "1850/1850 [==============================] - 20s 11ms/step - loss: 0.2486 - val_loss: 0.2486 - _timestamp: 1653295438.0000 - _runtime: 2156.0000\n",
      "Epoch 104/200\n",
      " 194/1850 [==>...........................] - ETA: 18s - loss: 0.2447 - val_loss: 0.2447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x285112820> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/machine_learning/lib/python3.8/site-packages/backcall/backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/backcall/backcall.py?line=101'>102</a>\u001b[0m                 kwargs\u001b[39m.\u001b[39mpop(name)\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/backcall/backcall.py?line=102'>103</a>\u001b[0m \u001b[39m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/backcall/backcall.py?line=103'>104</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m callback(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:355\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=352'>353</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun\u001b[39m.\u001b[39mlog_code(root\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=353'>354</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39msaved code: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, res)\n\u001b[0;32m--> <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=354'>355</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend\u001b[39m.\u001b[39;49minterface\u001b[39m.\u001b[39;49mpublish_pause()\n",
      "File \u001b[0;32m~/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py:596\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py?line=593'>594</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpublish_pause\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py?line=594'>595</a>\u001b[0m     pause \u001b[39m=\u001b[39m pb\u001b[39m.\u001b[39mPauseRequest()\n\u001b[0;32m--> <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface.py?line=595'>596</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_publish_pause(pause)\n",
      "File \u001b[0;32m~/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py:279\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py?line=276'>277</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_publish_pause\u001b[39m(\u001b[39mself\u001b[39m, pause: pb\u001b[39m.\u001b[39mPauseRequest) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py?line=277'>278</a>\u001b[0m     rec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(pause\u001b[39m=\u001b[39mpause)\n\u001b[0;32m--> <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py?line=278'>279</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_publish(rec)\n",
      "File \u001b[0;32m~/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py:49\u001b[0m, in \u001b[0;36mInterfaceQueue._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_publish\u001b[39m(\u001b[39mself\u001b[39m, record: \u001b[39m\"\u001b[39m\u001b[39mpb.Record\u001b[39m\u001b[39m\"\u001b[39m, local: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_check \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m---> <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py?line=48'>49</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe wandb backend process has shutdown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m local:\n\u001b[1;32m     <a href='file:///Users/dylan/miniforge3/envs/machine_learning/lib/python3.8/site-packages/wandb/sdk/interface/interface_queue.py?line=50'>51</a>\u001b[0m         record\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mlocal \u001b[39m=\u001b[39m local\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "interpreter": {
   "hash": "23205ef78abf7f5af4964beab5f9ded12336195ed2328d55c854b6b73ae2064a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
